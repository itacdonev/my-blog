<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.189">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ita Ćirović Donev">
<meta name="dcterms.date" content="2023-04-03">
<meta name="description" content="Applied ML learning journey">

<title>Ita Ćirović Donev - Explainer: Building A Modeling Pipeline in PyTorch</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Ita Ćirović Donev</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html">About</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/itacdonev"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/itacdonevFM"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/ita-cirovic-donev-9821379/"><i class="bi bi-linkedin" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-reader-toggle nav-link" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Explainer: Building A Modeling Pipeline in PyTorch</h1>
            <p class="subtitle lead">Step-by-Step Guide to Building A Modeling Pipeline in PyTorch</p>
                                <div class="quarto-categories">
                <div class="quarto-category">deep learning</div>
                <div class="quarto-category">pytorch</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Ita Ćirović Donev </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 3, 2023</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>This notebook follows a step-by-step process of training a neural network in PyTorch. The <strong>objective is on learning the main processes and steps in constructing the modeling pipeline</strong>. We will consider a computer vision classification problem, i.e.&nbsp;using a deep learning model to classify images in predefined categories.</p>
<p>When building a deep learning model there are five main things you should consider, namely: - data availability and structure: construct a <strong>dataloader</strong> for each dataset - model architecture: define a <strong>model class</strong> - define a modeling pipeline with: - hyperparameters - loss function and the optimizers - model metrics</p>
<p>Consider the following figure below where the central point is the training and validation box to which we feed the information from our data, the model architecture, etc. to obtain the trained model with its results in the form of a model loss and metrics. This trained model, we can then use to further analyze the resutls on the test set and if all goes well, implement it in production.</p>
<p><img src="index_files/figure-html/17a14767-dadc-4c42-b2f5-6df4fb85cae6.jpg" class="img-fluid" alt="DL components.jpg"> <cite>Figure 1. Overview of the components of deep learning modeling pipeline</cite><br><br></p>
<p>Since this is our first step in training a neural network in PyTorch we will <strong>focus on constructing the modeling pipeline</strong>, i.e.&nbsp;the training and validation box in the above figure, which we can then use in other more complex problems. For this reason we will use the MNIST dataset provided in PyTorch. In the next notebook, we will explore further by using a more complex dataset to demonstrate the importance of constructing a custom dataset and related topics.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:03.187493Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:03.187057Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:04.701778Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:04.700608Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:03.187429Z&quot;}" data-trusted="true" data-execution_count="3">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.colors <span class="im">as</span> mcolors</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.cm <span class="im">as</span> cm</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> termcolor <span class="im">import</span> colored</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nbdev</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># PyTorch</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> ToTensor</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> SubsetRandomSampler</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>After imports we define plot style and global variables. The purpose of global variables are such that they don’t change during the course of the notebook, which is why we define them at the beginning of the notebook.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:04.705152Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:04.704665Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:04.711384Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:04.710586Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:04.705122Z&quot;}" data-trusted="true" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting style</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'ggplot'</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Global variables</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>DATA_DIR <span class="op">=</span> Path(<span class="st">'/kaggle/working/data/'</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>MODELS_DIR <span class="op">=</span> Path(<span class="st">'/kaggle/working/models/'</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>MODELS_DIR.mkdir(parents<span class="op">=</span><span class="va">True</span>, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>SEED <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Define custom colors for the labels</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">"#D9D2D8"</span>,<span class="st">"#F2BBC9"</span>, <span class="st">"#BF849A"</span>, <span class="st">"#8C7A89"</span>, <span class="st">"#9AC7D9"</span>, </span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>          <span class="st">"#82C0D9"</span>, <span class="st">"#7DABB3"</span>, <span class="st">"#8F9FBF"</span>, <span class="st">"#737F99"</span>, <span class="st">"#566073"</span>]</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>cmap <span class="op">=</span> mcolors.ListedColormap(colors)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="datasets-and-dataloaders" class="level1">
<h1>Datasets and Dataloaders</h1>
<p>To train any machine learning model we first need data. For this project we will use the famous <a href="https://pytorch.org/vision/stable/generated/torchvision.datasets.MNIST.html#torchvision.datasets.MNIST">MNIST dataset</a> comprised of images of digits from 0 to 9. Our task is to predict the digit based on the image provided. The dataset is already included in the <code>dataset</code> module of <code>torchvision</code> library. The <code>dataset</code> module provides a collection of datasets. For further information see this <a href="https://pytorch.org/vision/stable/datasets.html">link</a>.</p>
<p>To download the dataset we need to provide at least the following arguments: - <code>root</code>: specifies where to save the downloaded files, - <code>train</code>: specifies whether to download the train set (<code>True</code>) or the test set (<code>False</code>); and - <code>download</code>: specifies whether to download the dataset. Note that if the data already exists locally in the provided <code>root</code> argument, the data will not be downloaded again.</p>
<p><strong>It is worth noting that the downloaded dataset will be processed as a PyTorch <code>DataSet</code>. This will enable easy loading of input data into the training and validaiton pipeline.</strong></p>
<p>To download the datasets and save both to <code>DATA_DIR</code> directory we can use the following code:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:04.713280Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:04.712739Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:04.810652Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:04.809730Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:04.713246Z&quot;}" data-trusted="true" data-execution_count="5">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Train set</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>data_train <span class="op">=</span> datasets.MNIST(root<span class="op">=</span>DATA_DIR, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Test set</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>data_test <span class="op">=</span> datasets.MNIST(root<span class="op">=</span>DATA_DIR, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>There are additional arguments such as <code>transform</code> which transforms the data. To illustrate each step separately we will use this option later on.</p>
<p>We can check how many images are in the training and test set using <code>len</code>. To obtain more information about the structure of each image we can use <code>.data.shape</code> which gives us the number of images and the size of each image, i.e.&nbsp;height and width.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:04.812466Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:04.812142Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:04.818849Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:04.817087Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:04.812414Z&quot;}" data-trusted="true" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Train data: </span><span class="sc">{</span><span class="bu">len</span>(data_train)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Test data: </span><span class="sc">{</span><span class="bu">len</span>(data_test)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Train: </span><span class="sc">{</span>data_train<span class="sc">.</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Test: </span><span class="sc">{</span>data_test<span class="sc">.</span>data<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Train data: 60000
Test data: 10000

Train: torch.Size([60000, 28, 28])
Test: torch.Size([10000, 28, 28])</code></pre>
</div>
</div>
<p>So in total there are 70000 images of handrwitten digits, where each is of size 28 by 28 pixels. Since the data is processed as a PyTorch dataset we know that each element of <code>data_train</code> is a tuple of inputs (images) and labels. To check the type of the input data we can use <code>type()</code> as shown below:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:04.820852Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:04.820532Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:04.830997Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:04.830002Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:04.820822Z&quot;}" data-trusted="true" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>img, label <span class="op">=</span> data_train[<span class="dv">0</span>]</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">type</span>(img))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'PIL.Image.Image'&gt;</code></pre>
</div>
</div>
<p>Since we haven’t applied any transformations on the images, the data types of our input data is still a PIL image. Note that a computer can not take an image as an input data point of this form. We will have to transform it into numbers, i.e.&nbsp;tensors. Before we go and do this let’s see how some of the images look like along with their corresponding target label. Below we define a simple plotting function which takes 9 random images from the training data and plots them using the blue gradient color.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Note that if we had transformed the images into tensors we would have shape of <code>[1,28,28]</code> for one image. In order to use the below function we need to change line <code>plt.imshow(img, cmap='Blues')</code> to <code>plt.imshow(img.squeeze(), cmap='Blues')</code>. The method <code>squeeze()</code> removes any dimension of 1.</p>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:04.833319Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:04.832553Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:04.839820Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:04.839032Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:04.833288Z&quot;}" data-trusted="true" data-execution_count="8">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_sample(data):</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Ref: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"""</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">4</span>,<span class="dv">4</span>))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    cols, rows <span class="op">=</span> <span class="dv">3</span>,<span class="dv">3</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, cols<span class="op">*</span>rows<span class="op">+</span><span class="dv">1</span>):</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        sample_idx <span class="op">=</span> torch.randint(<span class="bu">len</span>(data), size<span class="op">=</span>(<span class="dv">1</span>,)).item()</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get image and the corresponding label</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>        img, label <span class="op">=</span> data[sample_idx]</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        fig.add_subplot(rows,cols,i)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        plt.imshow(img, cmap<span class="op">=</span><span class="st">'Blues'</span>)</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="ss">f'Label: </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">'</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">"off"</span>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:04.841534Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:04.841122Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.141235Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.140127Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:04.841507Z&quot;}" data-trusted="true" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>show_sample(data_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-8-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Each of the images is composed of pixels ranging from 0 to 255, where 0 represents white and 255 black. Let’s transform the image to tensors and visualize it. We will apply <code>ToTensor()</code> which transforms the pixel values to the values in range of <code>(0,1)</code>.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.143378Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.142709Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.151878Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.150571Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.143333Z&quot;}" data-trusted="true" data-execution_count="10">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the first image and its label from the dataset</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>imgT <span class="op">=</span> ToTensor()(img)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Image dimension: </span><span class="sc">{</span>imgT<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Label: </span><span class="sc">{</span>label<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Image dimension: torch.Size([1, 28, 28])
Label: 5</code></pre>
</div>
</div>
<p>So the image size is 28 by 28 pixels and the first image should represent digit 5. Let’s see the pixel data with gradient colors for better visualization. We will use pandas <code>style</code> to apply the gradient effect. Since our image is of rank 3 in order to convert it to a pandas dataframe we need to remove the first dimension. We will do this using the <code>numpy</code> <code>squeeze()</code> which removes axes of length 1. Below image gives us the normalized pixel representation of the first digit image in the training sample. The label for this image is 5.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.153768Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.153392Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.307088Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.306173Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.153730Z&quot;}" data-trusted="true" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>dfimg <span class="op">=</span> pd.DataFrame(imgT.squeeze().numpy())</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>dfimg.style.set_properties(<span class="op">**</span>{<span class="st">'font-size'</span>:<span class="st">'6pt'</span>})<span class="op">\</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>           .background_gradient(<span class="st">'Blues'</span>)<span class="op">\</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>           .<span class="bu">format</span>(precision<span class="op">=</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">

<style type="text/css">
#T_a5791_row0_col0, #T_a5791_row0_col1, #T_a5791_row0_col2, #T_a5791_row0_col3, #T_a5791_row0_col4, #T_a5791_row0_col5, #T_a5791_row0_col6, #T_a5791_row0_col7, #T_a5791_row0_col8, #T_a5791_row0_col9, #T_a5791_row0_col10, #T_a5791_row0_col11, #T_a5791_row0_col12, #T_a5791_row0_col13, #T_a5791_row0_col14, #T_a5791_row0_col15, #T_a5791_row0_col16, #T_a5791_row0_col17, #T_a5791_row0_col18, #T_a5791_row0_col19, #T_a5791_row0_col20, #T_a5791_row0_col21, #T_a5791_row0_col22, #T_a5791_row0_col23, #T_a5791_row0_col24, #T_a5791_row0_col25, #T_a5791_row0_col26, #T_a5791_row0_col27, #T_a5791_row1_col0, #T_a5791_row1_col1, #T_a5791_row1_col2, #T_a5791_row1_col3, #T_a5791_row1_col4, #T_a5791_row1_col5, #T_a5791_row1_col6, #T_a5791_row1_col7, #T_a5791_row1_col8, #T_a5791_row1_col9, #T_a5791_row1_col10, #T_a5791_row1_col11, #T_a5791_row1_col12, #T_a5791_row1_col13, #T_a5791_row1_col14, #T_a5791_row1_col15, #T_a5791_row1_col16, #T_a5791_row1_col17, #T_a5791_row1_col18, #T_a5791_row1_col19, #T_a5791_row1_col20, #T_a5791_row1_col21, #T_a5791_row1_col22, #T_a5791_row1_col23, #T_a5791_row1_col24, #T_a5791_row1_col25, #T_a5791_row1_col26, #T_a5791_row1_col27, #T_a5791_row2_col0, #T_a5791_row2_col1, #T_a5791_row2_col2, #T_a5791_row2_col3, #T_a5791_row2_col4, #T_a5791_row2_col5, #T_a5791_row2_col6, #T_a5791_row2_col7, #T_a5791_row2_col8, #T_a5791_row2_col9, #T_a5791_row2_col10, #T_a5791_row2_col11, #T_a5791_row2_col12, #T_a5791_row2_col13, #T_a5791_row2_col14, #T_a5791_row2_col15, #T_a5791_row2_col16, #T_a5791_row2_col17, #T_a5791_row2_col18, #T_a5791_row2_col19, #T_a5791_row2_col20, #T_a5791_row2_col21, #T_a5791_row2_col22, #T_a5791_row2_col23, #T_a5791_row2_col24, #T_a5791_row2_col25, #T_a5791_row2_col26, #T_a5791_row2_col27, #T_a5791_row3_col0, #T_a5791_row3_col1, #T_a5791_row3_col2, #T_a5791_row3_col3, #T_a5791_row3_col4, #T_a5791_row3_col5, #T_a5791_row3_col6, #T_a5791_row3_col7, #T_a5791_row3_col8, #T_a5791_row3_col9, #T_a5791_row3_col10, #T_a5791_row3_col11, #T_a5791_row3_col12, #T_a5791_row3_col13, #T_a5791_row3_col14, #T_a5791_row3_col15, #T_a5791_row3_col16, #T_a5791_row3_col17, #T_a5791_row3_col18, #T_a5791_row3_col19, #T_a5791_row3_col20, #T_a5791_row3_col21, #T_a5791_row3_col22, #T_a5791_row3_col23, #T_a5791_row3_col24, #T_a5791_row3_col25, #T_a5791_row3_col26, #T_a5791_row3_col27, #T_a5791_row4_col0, #T_a5791_row4_col1, #T_a5791_row4_col2, #T_a5791_row4_col3, #T_a5791_row4_col4, #T_a5791_row4_col5, #T_a5791_row4_col6, #T_a5791_row4_col7, #T_a5791_row4_col8, #T_a5791_row4_col9, #T_a5791_row4_col10, #T_a5791_row4_col11, #T_a5791_row4_col12, #T_a5791_row4_col13, #T_a5791_row4_col14, #T_a5791_row4_col15, #T_a5791_row4_col16, #T_a5791_row4_col17, #T_a5791_row4_col18, #T_a5791_row4_col19, #T_a5791_row4_col20, #T_a5791_row4_col21, #T_a5791_row4_col22, #T_a5791_row4_col23, #T_a5791_row4_col24, #T_a5791_row4_col25, #T_a5791_row4_col26, #T_a5791_row4_col27, #T_a5791_row5_col0, #T_a5791_row5_col1, #T_a5791_row5_col2, #T_a5791_row5_col3, #T_a5791_row5_col4, #T_a5791_row5_col5, #T_a5791_row5_col6, #T_a5791_row5_col7, #T_a5791_row5_col8, #T_a5791_row5_col9, #T_a5791_row5_col10, #T_a5791_row5_col11, #T_a5791_row5_col24, #T_a5791_row5_col25, #T_a5791_row5_col26, #T_a5791_row5_col27, #T_a5791_row6_col0, #T_a5791_row6_col1, #T_a5791_row6_col2, #T_a5791_row6_col3, #T_a5791_row6_col4, #T_a5791_row6_col5, #T_a5791_row6_col6, #T_a5791_row6_col7, #T_a5791_row6_col24, #T_a5791_row6_col25, #T_a5791_row6_col26, #T_a5791_row6_col27, #T_a5791_row7_col0, #T_a5791_row7_col1, #T_a5791_row7_col2, #T_a5791_row7_col3, #T_a5791_row7_col4, #T_a5791_row7_col5, #T_a5791_row7_col6, #T_a5791_row7_col23, #T_a5791_row7_col24, #T_a5791_row7_col25, #T_a5791_row7_col26, #T_a5791_row7_col27, #T_a5791_row8_col0, #T_a5791_row8_col1, #T_a5791_row8_col2, #T_a5791_row8_col3, #T_a5791_row8_col4, #T_a5791_row8_col5, #T_a5791_row8_col6, #T_a5791_row8_col18, #T_a5791_row8_col19, #T_a5791_row8_col20, #T_a5791_row8_col21, #T_a5791_row8_col22, #T_a5791_row8_col23, #T_a5791_row8_col24, #T_a5791_row8_col25, #T_a5791_row8_col26, #T_a5791_row8_col27, #T_a5791_row9_col0, #T_a5791_row9_col1, #T_a5791_row9_col2, #T_a5791_row9_col3, #T_a5791_row9_col4, #T_a5791_row9_col5, #T_a5791_row9_col6, #T_a5791_row9_col7, #T_a5791_row9_col15, #T_a5791_row9_col18, #T_a5791_row9_col19, #T_a5791_row9_col20, #T_a5791_row9_col21, #T_a5791_row9_col22, #T_a5791_row9_col23, #T_a5791_row9_col24, #T_a5791_row9_col25, #T_a5791_row9_col26, #T_a5791_row9_col27, #T_a5791_row10_col0, #T_a5791_row10_col1, #T_a5791_row10_col2, #T_a5791_row10_col3, #T_a5791_row10_col4, #T_a5791_row10_col5, #T_a5791_row10_col6, #T_a5791_row10_col7, #T_a5791_row10_col8, #T_a5791_row10_col14, #T_a5791_row10_col15, #T_a5791_row10_col16, #T_a5791_row10_col17, #T_a5791_row10_col18, #T_a5791_row10_col19, #T_a5791_row10_col20, #T_a5791_row10_col21, #T_a5791_row10_col22, #T_a5791_row10_col23, #T_a5791_row10_col24, #T_a5791_row10_col25, #T_a5791_row10_col26, #T_a5791_row10_col27, #T_a5791_row11_col0, #T_a5791_row11_col1, #T_a5791_row11_col2, #T_a5791_row11_col3, #T_a5791_row11_col4, #T_a5791_row11_col5, #T_a5791_row11_col6, #T_a5791_row11_col7, #T_a5791_row11_col8, #T_a5791_row11_col9, #T_a5791_row11_col10, #T_a5791_row11_col15, #T_a5791_row11_col16, #T_a5791_row11_col17, #T_a5791_row11_col18, #T_a5791_row11_col19, #T_a5791_row11_col20, #T_a5791_row11_col21, #T_a5791_row11_col22, #T_a5791_row11_col23, #T_a5791_row11_col24, #T_a5791_row11_col25, #T_a5791_row11_col26, #T_a5791_row11_col27, #T_a5791_row12_col0, #T_a5791_row12_col1, #T_a5791_row12_col2, #T_a5791_row12_col3, #T_a5791_row12_col4, #T_a5791_row12_col5, #T_a5791_row12_col6, #T_a5791_row12_col7, #T_a5791_row12_col8, #T_a5791_row12_col9, #T_a5791_row12_col10, #T_a5791_row12_col15, #T_a5791_row12_col16, #T_a5791_row12_col17, #T_a5791_row12_col18, #T_a5791_row12_col19, #T_a5791_row12_col20, #T_a5791_row12_col21, #T_a5791_row12_col22, #T_a5791_row12_col23, #T_a5791_row12_col24, #T_a5791_row12_col25, #T_a5791_row12_col26, #T_a5791_row12_col27, #T_a5791_row13_col0, #T_a5791_row13_col1, #T_a5791_row13_col2, #T_a5791_row13_col3, #T_a5791_row13_col4, #T_a5791_row13_col5, #T_a5791_row13_col6, #T_a5791_row13_col7, #T_a5791_row13_col8, #T_a5791_row13_col9, #T_a5791_row13_col10, #T_a5791_row13_col11, #T_a5791_row13_col18, #T_a5791_row13_col19, #T_a5791_row13_col20, #T_a5791_row13_col21, #T_a5791_row13_col22, #T_a5791_row13_col23, #T_a5791_row13_col24, #T_a5791_row13_col25, #T_a5791_row13_col26, #T_a5791_row13_col27, #T_a5791_row14_col0, #T_a5791_row14_col1, #T_a5791_row14_col2, #T_a5791_row14_col3, #T_a5791_row14_col4, #T_a5791_row14_col5, #T_a5791_row14_col6, #T_a5791_row14_col7, #T_a5791_row14_col8, #T_a5791_row14_col9, #T_a5791_row14_col10, #T_a5791_row14_col11, #T_a5791_row14_col12, #T_a5791_row14_col19, #T_a5791_row14_col20, #T_a5791_row14_col21, #T_a5791_row14_col22, #T_a5791_row14_col23, #T_a5791_row14_col24, #T_a5791_row14_col25, #T_a5791_row14_col26, #T_a5791_row14_col27, #T_a5791_row15_col0, #T_a5791_row15_col1, #T_a5791_row15_col2, #T_a5791_row15_col3, #T_a5791_row15_col4, #T_a5791_row15_col5, #T_a5791_row15_col6, #T_a5791_row15_col7, #T_a5791_row15_col8, #T_a5791_row15_col9, #T_a5791_row15_col10, #T_a5791_row15_col11, #T_a5791_row15_col12, #T_a5791_row15_col13, #T_a5791_row15_col20, #T_a5791_row15_col21, #T_a5791_row15_col22, #T_a5791_row15_col23, #T_a5791_row15_col24, #T_a5791_row15_col25, #T_a5791_row15_col26, #T_a5791_row15_col27, #T_a5791_row16_col0, #T_a5791_row16_col1, #T_a5791_row16_col2, #T_a5791_row16_col3, #T_a5791_row16_col4, #T_a5791_row16_col5, #T_a5791_row16_col6, #T_a5791_row16_col7, #T_a5791_row16_col8, #T_a5791_row16_col9, #T_a5791_row16_col10, #T_a5791_row16_col11, #T_a5791_row16_col12, #T_a5791_row16_col13, #T_a5791_row16_col14, #T_a5791_row16_col20, #T_a5791_row16_col21, #T_a5791_row16_col22, #T_a5791_row16_col23, #T_a5791_row16_col24, #T_a5791_row16_col25, #T_a5791_row16_col26, #T_a5791_row16_col27, #T_a5791_row17_col0, #T_a5791_row17_col1, #T_a5791_row17_col2, #T_a5791_row17_col3, #T_a5791_row17_col4, #T_a5791_row17_col5, #T_a5791_row17_col6, #T_a5791_row17_col7, #T_a5791_row17_col8, #T_a5791_row17_col9, #T_a5791_row17_col10, #T_a5791_row17_col11, #T_a5791_row17_col12, #T_a5791_row17_col13, #T_a5791_row17_col14, #T_a5791_row17_col15, #T_a5791_row17_col16, #T_a5791_row17_col21, #T_a5791_row17_col22, #T_a5791_row17_col23, #T_a5791_row17_col24, #T_a5791_row17_col25, #T_a5791_row17_col26, #T_a5791_row17_col27, #T_a5791_row18_col0, #T_a5791_row18_col1, #T_a5791_row18_col2, #T_a5791_row18_col3, #T_a5791_row18_col4, #T_a5791_row18_col5, #T_a5791_row18_col6, #T_a5791_row18_col7, #T_a5791_row18_col8, #T_a5791_row18_col9, #T_a5791_row18_col10, #T_a5791_row18_col11, #T_a5791_row18_col12, #T_a5791_row18_col13, #T_a5791_row18_col21, #T_a5791_row18_col22, #T_a5791_row18_col23, #T_a5791_row18_col24, #T_a5791_row18_col25, #T_a5791_row18_col26, #T_a5791_row18_col27, #T_a5791_row19_col0, #T_a5791_row19_col1, #T_a5791_row19_col2, #T_a5791_row19_col3, #T_a5791_row19_col4, #T_a5791_row19_col5, #T_a5791_row19_col6, #T_a5791_row19_col7, #T_a5791_row19_col8, #T_a5791_row19_col9, #T_a5791_row19_col10, #T_a5791_row19_col11, #T_a5791_row19_col20, #T_a5791_row19_col21, #T_a5791_row19_col22, #T_a5791_row19_col23, #T_a5791_row19_col24, #T_a5791_row19_col25, #T_a5791_row19_col26, #T_a5791_row19_col27, #T_a5791_row20_col0, #T_a5791_row20_col1, #T_a5791_row20_col2, #T_a5791_row20_col3, #T_a5791_row20_col4, #T_a5791_row20_col5, #T_a5791_row20_col6, #T_a5791_row20_col7, #T_a5791_row20_col8, #T_a5791_row20_col9, #T_a5791_row20_col19, #T_a5791_row20_col20, #T_a5791_row20_col21, #T_a5791_row20_col22, #T_a5791_row20_col23, #T_a5791_row20_col24, #T_a5791_row20_col25, #T_a5791_row20_col26, #T_a5791_row20_col27, #T_a5791_row21_col0, #T_a5791_row21_col1, #T_a5791_row21_col2, #T_a5791_row21_col3, #T_a5791_row21_col4, #T_a5791_row21_col5, #T_a5791_row21_col6, #T_a5791_row21_col7, #T_a5791_row21_col18, #T_a5791_row21_col19, #T_a5791_row21_col20, #T_a5791_row21_col21, #T_a5791_row21_col22, #T_a5791_row21_col23, #T_a5791_row21_col24, #T_a5791_row21_col25, #T_a5791_row21_col26, #T_a5791_row21_col27, #T_a5791_row22_col0, #T_a5791_row22_col1, #T_a5791_row22_col2, #T_a5791_row22_col3, #T_a5791_row22_col4, #T_a5791_row22_col5, #T_a5791_row22_col16, #T_a5791_row22_col17, #T_a5791_row22_col18, #T_a5791_row22_col19, #T_a5791_row22_col20, #T_a5791_row22_col21, #T_a5791_row22_col22, #T_a5791_row22_col23, #T_a5791_row22_col24, #T_a5791_row22_col25, #T_a5791_row22_col26, #T_a5791_row22_col27, #T_a5791_row23_col0, #T_a5791_row23_col1, #T_a5791_row23_col2, #T_a5791_row23_col3, #T_a5791_row23_col14, #T_a5791_row23_col15, #T_a5791_row23_col16, #T_a5791_row23_col17, #T_a5791_row23_col18, #T_a5791_row23_col19, #T_a5791_row23_col20, #T_a5791_row23_col21, #T_a5791_row23_col22, #T_a5791_row23_col23, #T_a5791_row23_col24, #T_a5791_row23_col25, #T_a5791_row23_col26, #T_a5791_row23_col27, #T_a5791_row24_col0, #T_a5791_row24_col1, #T_a5791_row24_col2, #T_a5791_row24_col3, #T_a5791_row24_col12, #T_a5791_row24_col13, #T_a5791_row24_col14, #T_a5791_row24_col15, #T_a5791_row24_col16, #T_a5791_row24_col17, #T_a5791_row24_col18, #T_a5791_row24_col19, #T_a5791_row24_col20, #T_a5791_row24_col21, #T_a5791_row24_col22, #T_a5791_row24_col23, #T_a5791_row24_col24, #T_a5791_row24_col25, #T_a5791_row24_col26, #T_a5791_row24_col27, #T_a5791_row25_col0, #T_a5791_row25_col1, #T_a5791_row25_col2, #T_a5791_row25_col3, #T_a5791_row25_col4, #T_a5791_row25_col5, #T_a5791_row25_col6, #T_a5791_row25_col7, #T_a5791_row25_col8, #T_a5791_row25_col9, #T_a5791_row25_col10, #T_a5791_row25_col11, #T_a5791_row25_col12, #T_a5791_row25_col13, #T_a5791_row25_col14, #T_a5791_row25_col15, #T_a5791_row25_col16, #T_a5791_row25_col17, #T_a5791_row25_col18, #T_a5791_row25_col19, #T_a5791_row25_col20, #T_a5791_row25_col21, #T_a5791_row25_col22, #T_a5791_row25_col23, #T_a5791_row25_col24, #T_a5791_row25_col25, #T_a5791_row25_col26, #T_a5791_row25_col27, #T_a5791_row26_col0, #T_a5791_row26_col1, #T_a5791_row26_col2, #T_a5791_row26_col3, #T_a5791_row26_col4, #T_a5791_row26_col5, #T_a5791_row26_col6, #T_a5791_row26_col7, #T_a5791_row26_col8, #T_a5791_row26_col9, #T_a5791_row26_col10, #T_a5791_row26_col11, #T_a5791_row26_col12, #T_a5791_row26_col13, #T_a5791_row26_col14, #T_a5791_row26_col15, #T_a5791_row26_col16, #T_a5791_row26_col17, #T_a5791_row26_col18, #T_a5791_row26_col19, #T_a5791_row26_col20, #T_a5791_row26_col21, #T_a5791_row26_col22, #T_a5791_row26_col23, #T_a5791_row26_col24, #T_a5791_row26_col25, #T_a5791_row26_col26, #T_a5791_row26_col27, #T_a5791_row27_col0, #T_a5791_row27_col1, #T_a5791_row27_col2, #T_a5791_row27_col3, #T_a5791_row27_col4, #T_a5791_row27_col5, #T_a5791_row27_col6, #T_a5791_row27_col7, #T_a5791_row27_col8, #T_a5791_row27_col9, #T_a5791_row27_col10, #T_a5791_row27_col11, #T_a5791_row27_col12, #T_a5791_row27_col13, #T_a5791_row27_col14, #T_a5791_row27_col15, #T_a5791_row27_col16, #T_a5791_row27_col17, #T_a5791_row27_col18, #T_a5791_row27_col19, #T_a5791_row27_col20, #T_a5791_row27_col21, #T_a5791_row27_col22, #T_a5791_row27_col23, #T_a5791_row27_col24, #T_a5791_row27_col25, #T_a5791_row27_col26, #T_a5791_row27_col27 {
  font-size: 6pt;
  background-color: #f7fbff;
  color: #000000;
}
#T_a5791_row5_col12 {
  font-size: 6pt;
  background-color: #f5f9fe;
  color: #000000;
}
#T_a5791_row5_col13, #T_a5791_row5_col14, #T_a5791_row5_col15, #T_a5791_row8_col7, #T_a5791_row22_col6 {
  font-size: 6pt;
  background-color: #e9f2fa;
  color: #000000;
}
#T_a5791_row5_col16 {
  font-size: 6pt;
  background-color: #6caed6;
  color: #f1f1f1;
}
#T_a5791_row5_col17 {
  font-size: 6pt;
  background-color: #5fa6d1;
  color: #f1f1f1;
}
#T_a5791_row5_col18 {
  font-size: 6pt;
  background-color: #3080bd;
  color: #f1f1f1;
}
#T_a5791_row5_col19 {
  font-size: 6pt;
  background-color: #e3eef8;
  color: #000000;
}
#T_a5791_row5_col20 {
  font-size: 6pt;
  background-color: #3a8ac2;
  color: #f1f1f1;
}
#T_a5791_row5_col21, #T_a5791_row5_col22, #T_a5791_row5_col23, #T_a5791_row6_col13, #T_a5791_row6_col14, #T_a5791_row6_col15, #T_a5791_row6_col16, #T_a5791_row6_col17, #T_a5791_row6_col20, #T_a5791_row7_col9, #T_a5791_row7_col10, #T_a5791_row7_col11, #T_a5791_row7_col12, #T_a5791_row7_col13, #T_a5791_row7_col14, #T_a5791_row7_col15, #T_a5791_row7_col16, #T_a5791_row8_col9, #T_a5791_row8_col10, #T_a5791_row8_col11, #T_a5791_row8_col12, #T_a5791_row8_col13, #T_a5791_row9_col11, #T_a5791_row9_col12, #T_a5791_row10_col12, #T_a5791_row11_col12, #T_a5791_row12_col13, #T_a5791_row14_col15, #T_a5791_row14_col16, #T_a5791_row15_col16, #T_a5791_row15_col17, #T_a5791_row16_col18, #T_a5791_row17_col18, #T_a5791_row17_col19, #T_a5791_row18_col17, #T_a5791_row18_col18, #T_a5791_row19_col15, #T_a5791_row19_col16, #T_a5791_row19_col17, #T_a5791_row20_col13, #T_a5791_row20_col14, #T_a5791_row20_col15, #T_a5791_row20_col16, #T_a5791_row21_col11, #T_a5791_row21_col12, #T_a5791_row21_col13, #T_a5791_row21_col14, #T_a5791_row22_col9, #T_a5791_row22_col10, #T_a5791_row22_col11, #T_a5791_row22_col12, #T_a5791_row23_col7, #T_a5791_row23_col8, #T_a5791_row23_col9, #T_a5791_row23_col10, #T_a5791_row24_col4, #T_a5791_row24_col5, #T_a5791_row24_col6, #T_a5791_row24_col7 {
  font-size: 6pt;
  background-color: #08306b;
  color: #f1f1f1;
}
#T_a5791_row6_col8 {
  font-size: 6pt;
  background-color: #dfecf7;
  color: #000000;
}
#T_a5791_row6_col9 {
  font-size: 6pt;
  background-color: #dbe9f6;
  color: #000000;
}
#T_a5791_row6_col10 {
  font-size: 6pt;
  background-color: #9fcae1;
  color: #000000;
}
#T_a5791_row6_col11, #T_a5791_row9_col17, #T_a5791_row10_col11 {
  font-size: 6pt;
  background-color: #4896c8;
  color: #f1f1f1;
}
#T_a5791_row6_col12 {
  font-size: 6pt;
  background-color: #3585bf;
  color: #f1f1f1;
}
#T_a5791_row6_col18, #T_a5791_row13_col14 {
  font-size: 6pt;
  background-color: #084d96;
  color: #f1f1f1;
}
#T_a5791_row6_col19 {
  font-size: 6pt;
  background-color: #3181bd;
  color: #f1f1f1;
}
#T_a5791_row6_col21, #T_a5791_row14_col14 {
  font-size: 6pt;
  background-color: #083d7f;
  color: #f1f1f1;
}
#T_a5791_row6_col22 {
  font-size: 6pt;
  background-color: #1966ad;
  color: #f1f1f1;
}
#T_a5791_row6_col23 {
  font-size: 6pt;
  background-color: #69add5;
  color: #f1f1f1;
}
#T_a5791_row7_col7 {
  font-size: 6pt;
  background-color: #d1e2f3;
  color: #000000;
}
#T_a5791_row7_col8 {
  font-size: 6pt;
  background-color: #084082;
  color: #f1f1f1;
}
#T_a5791_row7_col17 {
  font-size: 6pt;
  background-color: #08326e;
  color: #f1f1f1;
}
#T_a5791_row7_col18, #T_a5791_row16_col16 {
  font-size: 6pt;
  background-color: #a0cbe2;
  color: #000000;
}
#T_a5791_row7_col19 {
  font-size: 6pt;
  background-color: #add0e6;
  color: #000000;
}
#T_a5791_row7_col20 {
  font-size: 6pt;
  background-color: #afd1e7;
  color: #000000;
}
#T_a5791_row7_col21 {
  font-size: 6pt;
  background-color: #ccdff1;
  color: #000000;
}
#T_a5791_row7_col22 {
  font-size: 6pt;
  background-color: #d8e7f5;
  color: #000000;
}
#T_a5791_row8_col8, #T_a5791_row22_col8 {
  font-size: 6pt;
  background-color: #0a539e;
  color: #f1f1f1;
}
#T_a5791_row8_col14, #T_a5791_row21_col15 {
  font-size: 6pt;
  background-color: #1a68ae;
  color: #f1f1f1;
}
#T_a5791_row8_col15 {
  font-size: 6pt;
  background-color: #2979b9;
  color: #f1f1f1;
}
#T_a5791_row8_col16 {
  font-size: 6pt;
  background-color: #083674;
  color: #f1f1f1;
}
#T_a5791_row8_col17, #T_a5791_row13_col13 {
  font-size: 6pt;
  background-color: #083c7d;
  color: #f1f1f1;
}
#T_a5791_row9_col8, #T_a5791_row22_col14 {
  font-size: 6pt;
  background-color: #b2d2e8;
  color: #000000;
}
#T_a5791_row9_col9 {
  font-size: 6pt;
  background-color: #4594c7;
  color: #f1f1f1;
}
#T_a5791_row9_col10 {
  font-size: 6pt;
  background-color: #8abfdd;
  color: #000000;
}
#T_a5791_row9_col13 {
  font-size: 6pt;
  background-color: #1561a9;
  color: #f1f1f1;
}
#T_a5791_row9_col14, #T_a5791_row12_col11, #T_a5791_row23_col13 {
  font-size: 6pt;
  background-color: #eef5fc;
  color: #000000;
}
#T_a5791_row9_col16 {
  font-size: 6pt;
  background-color: #d6e5f4;
  color: #000000;
}
#T_a5791_row10_col9 {
  font-size: 6pt;
  background-color: #ecf4fb;
  color: #000000;
}
#T_a5791_row10_col10, #T_a5791_row13_col17 {
  font-size: 6pt;
  background-color: #f6faff;
  color: #000000;
}
#T_a5791_row10_col13 {
  font-size: 6pt;
  background-color: #a4cce3;
  color: #000000;
}
#T_a5791_row11_col11 {
  font-size: 6pt;
  background-color: #5ba3d0;
  color: #f1f1f1;
}
#T_a5791_row11_col13, #T_a5791_row12_col12, #T_a5791_row16_col19 {
  font-size: 6pt;
  background-color: #2070b4;
  color: #f1f1f1;
}
#T_a5791_row11_col14, #T_a5791_row18_col20, #T_a5791_row21_col17 {
  font-size: 6pt;
  background-color: #f5fafe;
  color: #000000;
}
#T_a5791_row12_col14 {
  font-size: 6pt;
  background-color: #bed8ec;
  color: #000000;
}
#T_a5791_row13_col12 {
  font-size: 6pt;
  background-color: #dce9f6;
  color: #000000;
}
#T_a5791_row13_col15 {
  font-size: 6pt;
  background-color: #4090c5;
  color: #f1f1f1;
}
#T_a5791_row13_col16 {
  font-size: 6pt;
  background-color: #89bedc;
  color: #000000;
}
#T_a5791_row14_col13, #T_a5791_row21_col16 {
  font-size: 6pt;
  background-color: #b0d2e7;
  color: #000000;
}
#T_a5791_row14_col17 {
  font-size: 6pt;
  background-color: #77b5d9;
  color: #000000;
}
#T_a5791_row14_col18 {
  font-size: 6pt;
  background-color: #e3eef9;
  color: #000000;
}
#T_a5791_row15_col14 {
  font-size: 6pt;
  background-color: #d4e4f4;
  color: #000000;
}
#T_a5791_row15_col15 {
  font-size: 6pt;
  background-color: #2474b7;
  color: #f1f1f1;
}
#T_a5791_row15_col18 {
  font-size: 6pt;
  background-color: #4d99ca;
  color: #f1f1f1;
}
#T_a5791_row15_col19 {
  font-size: 6pt;
  background-color: #e2edf8;
  color: #000000;
}
#T_a5791_row16_col15, #T_a5791_row24_col11 {
  font-size: 6pt;
  background-color: #eaf3fb;
  color: #000000;
}
#T_a5791_row16_col17 {
  font-size: 6pt;
  background-color: #08316d;
  color: #f1f1f1;
}
#T_a5791_row17_col17 {
  font-size: 6pt;
  background-color: #083471;
  color: #f1f1f1;
}
#T_a5791_row17_col20 {
  font-size: 6pt;
  background-color: #c6dbef;
  color: #000000;
}
#T_a5791_row18_col14 {
  font-size: 6pt;
  background-color: #d3e4f3;
  color: #000000;
}
#T_a5791_row18_col15 {
  font-size: 6pt;
  background-color: #66abd4;
  color: #f1f1f1;
}
#T_a5791_row18_col16 {
  font-size: 6pt;
  background-color: #2777b8;
  color: #f1f1f1;
}
#T_a5791_row18_col19 {
  font-size: 6pt;
  background-color: #115ca5;
  color: #f1f1f1;
}
#T_a5791_row19_col12 {
  font-size: 6pt;
  background-color: #d9e7f5;
  color: #000000;
}
#T_a5791_row19_col13 {
  font-size: 6pt;
  background-color: #4f9bcb;
  color: #f1f1f1;
}
#T_a5791_row19_col14 {
  font-size: 6pt;
  background-color: #084990;
  color: #f1f1f1;
}
#T_a5791_row19_col18 {
  font-size: 6pt;
  background-color: #083370;
  color: #f1f1f1;
}
#T_a5791_row19_col19 {
  font-size: 6pt;
  background-color: #2575b7;
  color: #f1f1f1;
}
#T_a5791_row20_col10 {
  font-size: 6pt;
  background-color: #e4eff9;
  color: #000000;
}
#T_a5791_row20_col11 {
  font-size: 6pt;
  background-color: #7fb9da;
  color: #000000;
}
#T_a5791_row20_col12 {
  font-size: 6pt;
  background-color: #08519c;
  color: #f1f1f1;
}
#T_a5791_row20_col17 {
  font-size: 6pt;
  background-color: #1865ac;
  color: #f1f1f1;
}
#T_a5791_row20_col18 {
  font-size: 6pt;
  background-color: #b4d3e9;
  color: #000000;
}
#T_a5791_row21_col8 {
  font-size: 6pt;
  background-color: #e5eff9;
  color: #000000;
}
#T_a5791_row21_col9 {
  font-size: 6pt;
  background-color: #c3daee;
  color: #000000;
}
#T_a5791_row21_col10 {
  font-size: 6pt;
  background-color: #0e59a2;
  color: #f1f1f1;
}
#T_a5791_row22_col7 {
  font-size: 6pt;
  background-color: #3484bf;
  color: #f1f1f1;
}
#T_a5791_row22_col13 {
  font-size: 6pt;
  background-color: #1c6bb0;
  color: #f1f1f1;
}
#T_a5791_row22_col15 {
  font-size: 6pt;
  background-color: #f0f6fd;
  color: #000000;
}
#T_a5791_row23_col4 {
  font-size: 6pt;
  background-color: #92c4de;
  color: #000000;
}
#T_a5791_row23_col5 {
  font-size: 6pt;
  background-color: #3383be;
  color: #f1f1f1;
}
#T_a5791_row23_col6 {
  font-size: 6pt;
  background-color: #084c95;
  color: #f1f1f1;
}
#T_a5791_row23_col11 {
  font-size: 6pt;
  background-color: #083979;
  color: #f1f1f1;
}
#T_a5791_row23_col12 {
  font-size: 6pt;
  background-color: #63a8d3;
  color: #f1f1f1;
}
#T_a5791_row24_col8 {
  font-size: 6pt;
  background-color: #0f5aa3;
  color: #f1f1f1;
}
#T_a5791_row24_col9 {
  font-size: 6pt;
  background-color: #60a7d2;
  color: #f1f1f1;
}
#T_a5791_row24_col10 {
  font-size: 6pt;
  background-color: #64a9d3;
  color: #f1f1f1;
}
</style>
<table id="T_a5791_">
  <thead>
    <tr>
      <th class="blank level0">&nbsp;</th>
      <th class="col_heading level0 col0">0</th>
      <th class="col_heading level0 col1">1</th>
      <th class="col_heading level0 col2">2</th>
      <th class="col_heading level0 col3">3</th>
      <th class="col_heading level0 col4">4</th>
      <th class="col_heading level0 col5">5</th>
      <th class="col_heading level0 col6">6</th>
      <th class="col_heading level0 col7">7</th>
      <th class="col_heading level0 col8">8</th>
      <th class="col_heading level0 col9">9</th>
      <th class="col_heading level0 col10">10</th>
      <th class="col_heading level0 col11">11</th>
      <th class="col_heading level0 col12">12</th>
      <th class="col_heading level0 col13">13</th>
      <th class="col_heading level0 col14">14</th>
      <th class="col_heading level0 col15">15</th>
      <th class="col_heading level0 col16">16</th>
      <th class="col_heading level0 col17">17</th>
      <th class="col_heading level0 col18">18</th>
      <th class="col_heading level0 col19">19</th>
      <th class="col_heading level0 col20">20</th>
      <th class="col_heading level0 col21">21</th>
      <th class="col_heading level0 col22">22</th>
      <th class="col_heading level0 col23">23</th>
      <th class="col_heading level0 col24">24</th>
      <th class="col_heading level0 col25">25</th>
      <th class="col_heading level0 col26">26</th>
      <th class="col_heading level0 col27">27</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th id="T_a5791_level0_row0" class="row_heading level0 row0">0</th>
      <td id="T_a5791_row0_col0" class="data row0 col0">0.00</td>
      <td id="T_a5791_row0_col1" class="data row0 col1">0.00</td>
      <td id="T_a5791_row0_col2" class="data row0 col2">0.00</td>
      <td id="T_a5791_row0_col3" class="data row0 col3">0.00</td>
      <td id="T_a5791_row0_col4" class="data row0 col4">0.00</td>
      <td id="T_a5791_row0_col5" class="data row0 col5">0.00</td>
      <td id="T_a5791_row0_col6" class="data row0 col6">0.00</td>
      <td id="T_a5791_row0_col7" class="data row0 col7">0.00</td>
      <td id="T_a5791_row0_col8" class="data row0 col8">0.00</td>
      <td id="T_a5791_row0_col9" class="data row0 col9">0.00</td>
      <td id="T_a5791_row0_col10" class="data row0 col10">0.00</td>
      <td id="T_a5791_row0_col11" class="data row0 col11">0.00</td>
      <td id="T_a5791_row0_col12" class="data row0 col12">0.00</td>
      <td id="T_a5791_row0_col13" class="data row0 col13">0.00</td>
      <td id="T_a5791_row0_col14" class="data row0 col14">0.00</td>
      <td id="T_a5791_row0_col15" class="data row0 col15">0.00</td>
      <td id="T_a5791_row0_col16" class="data row0 col16">0.00</td>
      <td id="T_a5791_row0_col17" class="data row0 col17">0.00</td>
      <td id="T_a5791_row0_col18" class="data row0 col18">0.00</td>
      <td id="T_a5791_row0_col19" class="data row0 col19">0.00</td>
      <td id="T_a5791_row0_col20" class="data row0 col20">0.00</td>
      <td id="T_a5791_row0_col21" class="data row0 col21">0.00</td>
      <td id="T_a5791_row0_col22" class="data row0 col22">0.00</td>
      <td id="T_a5791_row0_col23" class="data row0 col23">0.00</td>
      <td id="T_a5791_row0_col24" class="data row0 col24">0.00</td>
      <td id="T_a5791_row0_col25" class="data row0 col25">0.00</td>
      <td id="T_a5791_row0_col26" class="data row0 col26">0.00</td>
      <td id="T_a5791_row0_col27" class="data row0 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row1" class="row_heading level0 row1">1</th>
      <td id="T_a5791_row1_col0" class="data row1 col0">0.00</td>
      <td id="T_a5791_row1_col1" class="data row1 col1">0.00</td>
      <td id="T_a5791_row1_col2" class="data row1 col2">0.00</td>
      <td id="T_a5791_row1_col3" class="data row1 col3">0.00</td>
      <td id="T_a5791_row1_col4" class="data row1 col4">0.00</td>
      <td id="T_a5791_row1_col5" class="data row1 col5">0.00</td>
      <td id="T_a5791_row1_col6" class="data row1 col6">0.00</td>
      <td id="T_a5791_row1_col7" class="data row1 col7">0.00</td>
      <td id="T_a5791_row1_col8" class="data row1 col8">0.00</td>
      <td id="T_a5791_row1_col9" class="data row1 col9">0.00</td>
      <td id="T_a5791_row1_col10" class="data row1 col10">0.00</td>
      <td id="T_a5791_row1_col11" class="data row1 col11">0.00</td>
      <td id="T_a5791_row1_col12" class="data row1 col12">0.00</td>
      <td id="T_a5791_row1_col13" class="data row1 col13">0.00</td>
      <td id="T_a5791_row1_col14" class="data row1 col14">0.00</td>
      <td id="T_a5791_row1_col15" class="data row1 col15">0.00</td>
      <td id="T_a5791_row1_col16" class="data row1 col16">0.00</td>
      <td id="T_a5791_row1_col17" class="data row1 col17">0.00</td>
      <td id="T_a5791_row1_col18" class="data row1 col18">0.00</td>
      <td id="T_a5791_row1_col19" class="data row1 col19">0.00</td>
      <td id="T_a5791_row1_col20" class="data row1 col20">0.00</td>
      <td id="T_a5791_row1_col21" class="data row1 col21">0.00</td>
      <td id="T_a5791_row1_col22" class="data row1 col22">0.00</td>
      <td id="T_a5791_row1_col23" class="data row1 col23">0.00</td>
      <td id="T_a5791_row1_col24" class="data row1 col24">0.00</td>
      <td id="T_a5791_row1_col25" class="data row1 col25">0.00</td>
      <td id="T_a5791_row1_col26" class="data row1 col26">0.00</td>
      <td id="T_a5791_row1_col27" class="data row1 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row2" class="row_heading level0 row2">2</th>
      <td id="T_a5791_row2_col0" class="data row2 col0">0.00</td>
      <td id="T_a5791_row2_col1" class="data row2 col1">0.00</td>
      <td id="T_a5791_row2_col2" class="data row2 col2">0.00</td>
      <td id="T_a5791_row2_col3" class="data row2 col3">0.00</td>
      <td id="T_a5791_row2_col4" class="data row2 col4">0.00</td>
      <td id="T_a5791_row2_col5" class="data row2 col5">0.00</td>
      <td id="T_a5791_row2_col6" class="data row2 col6">0.00</td>
      <td id="T_a5791_row2_col7" class="data row2 col7">0.00</td>
      <td id="T_a5791_row2_col8" class="data row2 col8">0.00</td>
      <td id="T_a5791_row2_col9" class="data row2 col9">0.00</td>
      <td id="T_a5791_row2_col10" class="data row2 col10">0.00</td>
      <td id="T_a5791_row2_col11" class="data row2 col11">0.00</td>
      <td id="T_a5791_row2_col12" class="data row2 col12">0.00</td>
      <td id="T_a5791_row2_col13" class="data row2 col13">0.00</td>
      <td id="T_a5791_row2_col14" class="data row2 col14">0.00</td>
      <td id="T_a5791_row2_col15" class="data row2 col15">0.00</td>
      <td id="T_a5791_row2_col16" class="data row2 col16">0.00</td>
      <td id="T_a5791_row2_col17" class="data row2 col17">0.00</td>
      <td id="T_a5791_row2_col18" class="data row2 col18">0.00</td>
      <td id="T_a5791_row2_col19" class="data row2 col19">0.00</td>
      <td id="T_a5791_row2_col20" class="data row2 col20">0.00</td>
      <td id="T_a5791_row2_col21" class="data row2 col21">0.00</td>
      <td id="T_a5791_row2_col22" class="data row2 col22">0.00</td>
      <td id="T_a5791_row2_col23" class="data row2 col23">0.00</td>
      <td id="T_a5791_row2_col24" class="data row2 col24">0.00</td>
      <td id="T_a5791_row2_col25" class="data row2 col25">0.00</td>
      <td id="T_a5791_row2_col26" class="data row2 col26">0.00</td>
      <td id="T_a5791_row2_col27" class="data row2 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row3" class="row_heading level0 row3">3</th>
      <td id="T_a5791_row3_col0" class="data row3 col0">0.00</td>
      <td id="T_a5791_row3_col1" class="data row3 col1">0.00</td>
      <td id="T_a5791_row3_col2" class="data row3 col2">0.00</td>
      <td id="T_a5791_row3_col3" class="data row3 col3">0.00</td>
      <td id="T_a5791_row3_col4" class="data row3 col4">0.00</td>
      <td id="T_a5791_row3_col5" class="data row3 col5">0.00</td>
      <td id="T_a5791_row3_col6" class="data row3 col6">0.00</td>
      <td id="T_a5791_row3_col7" class="data row3 col7">0.00</td>
      <td id="T_a5791_row3_col8" class="data row3 col8">0.00</td>
      <td id="T_a5791_row3_col9" class="data row3 col9">0.00</td>
      <td id="T_a5791_row3_col10" class="data row3 col10">0.00</td>
      <td id="T_a5791_row3_col11" class="data row3 col11">0.00</td>
      <td id="T_a5791_row3_col12" class="data row3 col12">0.00</td>
      <td id="T_a5791_row3_col13" class="data row3 col13">0.00</td>
      <td id="T_a5791_row3_col14" class="data row3 col14">0.00</td>
      <td id="T_a5791_row3_col15" class="data row3 col15">0.00</td>
      <td id="T_a5791_row3_col16" class="data row3 col16">0.00</td>
      <td id="T_a5791_row3_col17" class="data row3 col17">0.00</td>
      <td id="T_a5791_row3_col18" class="data row3 col18">0.00</td>
      <td id="T_a5791_row3_col19" class="data row3 col19">0.00</td>
      <td id="T_a5791_row3_col20" class="data row3 col20">0.00</td>
      <td id="T_a5791_row3_col21" class="data row3 col21">0.00</td>
      <td id="T_a5791_row3_col22" class="data row3 col22">0.00</td>
      <td id="T_a5791_row3_col23" class="data row3 col23">0.00</td>
      <td id="T_a5791_row3_col24" class="data row3 col24">0.00</td>
      <td id="T_a5791_row3_col25" class="data row3 col25">0.00</td>
      <td id="T_a5791_row3_col26" class="data row3 col26">0.00</td>
      <td id="T_a5791_row3_col27" class="data row3 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row4" class="row_heading level0 row4">4</th>
      <td id="T_a5791_row4_col0" class="data row4 col0">0.00</td>
      <td id="T_a5791_row4_col1" class="data row4 col1">0.00</td>
      <td id="T_a5791_row4_col2" class="data row4 col2">0.00</td>
      <td id="T_a5791_row4_col3" class="data row4 col3">0.00</td>
      <td id="T_a5791_row4_col4" class="data row4 col4">0.00</td>
      <td id="T_a5791_row4_col5" class="data row4 col5">0.00</td>
      <td id="T_a5791_row4_col6" class="data row4 col6">0.00</td>
      <td id="T_a5791_row4_col7" class="data row4 col7">0.00</td>
      <td id="T_a5791_row4_col8" class="data row4 col8">0.00</td>
      <td id="T_a5791_row4_col9" class="data row4 col9">0.00</td>
      <td id="T_a5791_row4_col10" class="data row4 col10">0.00</td>
      <td id="T_a5791_row4_col11" class="data row4 col11">0.00</td>
      <td id="T_a5791_row4_col12" class="data row4 col12">0.00</td>
      <td id="T_a5791_row4_col13" class="data row4 col13">0.00</td>
      <td id="T_a5791_row4_col14" class="data row4 col14">0.00</td>
      <td id="T_a5791_row4_col15" class="data row4 col15">0.00</td>
      <td id="T_a5791_row4_col16" class="data row4 col16">0.00</td>
      <td id="T_a5791_row4_col17" class="data row4 col17">0.00</td>
      <td id="T_a5791_row4_col18" class="data row4 col18">0.00</td>
      <td id="T_a5791_row4_col19" class="data row4 col19">0.00</td>
      <td id="T_a5791_row4_col20" class="data row4 col20">0.00</td>
      <td id="T_a5791_row4_col21" class="data row4 col21">0.00</td>
      <td id="T_a5791_row4_col22" class="data row4 col22">0.00</td>
      <td id="T_a5791_row4_col23" class="data row4 col23">0.00</td>
      <td id="T_a5791_row4_col24" class="data row4 col24">0.00</td>
      <td id="T_a5791_row4_col25" class="data row4 col25">0.00</td>
      <td id="T_a5791_row4_col26" class="data row4 col26">0.00</td>
      <td id="T_a5791_row4_col27" class="data row4 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row5" class="row_heading level0 row5">5</th>
      <td id="T_a5791_row5_col0" class="data row5 col0">0.00</td>
      <td id="T_a5791_row5_col1" class="data row5 col1">0.00</td>
      <td id="T_a5791_row5_col2" class="data row5 col2">0.00</td>
      <td id="T_a5791_row5_col3" class="data row5 col3">0.00</td>
      <td id="T_a5791_row5_col4" class="data row5 col4">0.00</td>
      <td id="T_a5791_row5_col5" class="data row5 col5">0.00</td>
      <td id="T_a5791_row5_col6" class="data row5 col6">0.00</td>
      <td id="T_a5791_row5_col7" class="data row5 col7">0.00</td>
      <td id="T_a5791_row5_col8" class="data row5 col8">0.00</td>
      <td id="T_a5791_row5_col9" class="data row5 col9">0.00</td>
      <td id="T_a5791_row5_col10" class="data row5 col10">0.00</td>
      <td id="T_a5791_row5_col11" class="data row5 col11">0.00</td>
      <td id="T_a5791_row5_col12" class="data row5 col12">0.01</td>
      <td id="T_a5791_row5_col13" class="data row5 col13">0.07</td>
      <td id="T_a5791_row5_col14" class="data row5 col14">0.07</td>
      <td id="T_a5791_row5_col15" class="data row5 col15">0.07</td>
      <td id="T_a5791_row5_col16" class="data row5 col16">0.49</td>
      <td id="T_a5791_row5_col17" class="data row5 col17">0.53</td>
      <td id="T_a5791_row5_col18" class="data row5 col18">0.69</td>
      <td id="T_a5791_row5_col19" class="data row5 col19">0.10</td>
      <td id="T_a5791_row5_col20" class="data row5 col20">0.65</td>
      <td id="T_a5791_row5_col21" class="data row5 col21">1.00</td>
      <td id="T_a5791_row5_col22" class="data row5 col22">0.97</td>
      <td id="T_a5791_row5_col23" class="data row5 col23">0.50</td>
      <td id="T_a5791_row5_col24" class="data row5 col24">0.00</td>
      <td id="T_a5791_row5_col25" class="data row5 col25">0.00</td>
      <td id="T_a5791_row5_col26" class="data row5 col26">0.00</td>
      <td id="T_a5791_row5_col27" class="data row5 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row6" class="row_heading level0 row6">6</th>
      <td id="T_a5791_row6_col0" class="data row6 col0">0.00</td>
      <td id="T_a5791_row6_col1" class="data row6 col1">0.00</td>
      <td id="T_a5791_row6_col2" class="data row6 col2">0.00</td>
      <td id="T_a5791_row6_col3" class="data row6 col3">0.00</td>
      <td id="T_a5791_row6_col4" class="data row6 col4">0.00</td>
      <td id="T_a5791_row6_col5" class="data row6 col5">0.00</td>
      <td id="T_a5791_row6_col6" class="data row6 col6">0.00</td>
      <td id="T_a5791_row6_col7" class="data row6 col7">0.00</td>
      <td id="T_a5791_row6_col8" class="data row6 col8">0.12</td>
      <td id="T_a5791_row6_col9" class="data row6 col9">0.14</td>
      <td id="T_a5791_row6_col10" class="data row6 col10">0.37</td>
      <td id="T_a5791_row6_col11" class="data row6 col11">0.60</td>
      <td id="T_a5791_row6_col12" class="data row6 col12">0.67</td>
      <td id="T_a5791_row6_col13" class="data row6 col13">0.99</td>
      <td id="T_a5791_row6_col14" class="data row6 col14">0.99</td>
      <td id="T_a5791_row6_col15" class="data row6 col15">0.99</td>
      <td id="T_a5791_row6_col16" class="data row6 col16">0.99</td>
      <td id="T_a5791_row6_col17" class="data row6 col17">0.99</td>
      <td id="T_a5791_row6_col18" class="data row6 col18">0.88</td>
      <td id="T_a5791_row6_col19" class="data row6 col19">0.67</td>
      <td id="T_a5791_row6_col20" class="data row6 col20">0.99</td>
      <td id="T_a5791_row6_col21" class="data row6 col21">0.95</td>
      <td id="T_a5791_row6_col22" class="data row6 col22">0.76</td>
      <td id="T_a5791_row6_col23" class="data row6 col23">0.25</td>
      <td id="T_a5791_row6_col24" class="data row6 col24">0.00</td>
      <td id="T_a5791_row6_col25" class="data row6 col25">0.00</td>
      <td id="T_a5791_row6_col26" class="data row6 col26">0.00</td>
      <td id="T_a5791_row6_col27" class="data row6 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row7" class="row_heading level0 row7">7</th>
      <td id="T_a5791_row7_col0" class="data row7 col0">0.00</td>
      <td id="T_a5791_row7_col1" class="data row7 col1">0.00</td>
      <td id="T_a5791_row7_col2" class="data row7 col2">0.00</td>
      <td id="T_a5791_row7_col3" class="data row7 col3">0.00</td>
      <td id="T_a5791_row7_col4" class="data row7 col4">0.00</td>
      <td id="T_a5791_row7_col5" class="data row7 col5">0.00</td>
      <td id="T_a5791_row7_col6" class="data row7 col6">0.00</td>
      <td id="T_a5791_row7_col7" class="data row7 col7">0.19</td>
      <td id="T_a5791_row7_col8" class="data row7 col8">0.93</td>
      <td id="T_a5791_row7_col9" class="data row7 col9">0.99</td>
      <td id="T_a5791_row7_col10" class="data row7 col10">0.99</td>
      <td id="T_a5791_row7_col11" class="data row7 col11">0.99</td>
      <td id="T_a5791_row7_col12" class="data row7 col12">0.99</td>
      <td id="T_a5791_row7_col13" class="data row7 col13">0.99</td>
      <td id="T_a5791_row7_col14" class="data row7 col14">0.99</td>
      <td id="T_a5791_row7_col15" class="data row7 col15">0.99</td>
      <td id="T_a5791_row7_col16" class="data row7 col16">0.99</td>
      <td id="T_a5791_row7_col17" class="data row7 col17">0.98</td>
      <td id="T_a5791_row7_col18" class="data row7 col18">0.36</td>
      <td id="T_a5791_row7_col19" class="data row7 col19">0.32</td>
      <td id="T_a5791_row7_col20" class="data row7 col20">0.32</td>
      <td id="T_a5791_row7_col21" class="data row7 col21">0.22</td>
      <td id="T_a5791_row7_col22" class="data row7 col22">0.15</td>
      <td id="T_a5791_row7_col23" class="data row7 col23">0.00</td>
      <td id="T_a5791_row7_col24" class="data row7 col24">0.00</td>
      <td id="T_a5791_row7_col25" class="data row7 col25">0.00</td>
      <td id="T_a5791_row7_col26" class="data row7 col26">0.00</td>
      <td id="T_a5791_row7_col27" class="data row7 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row8" class="row_heading level0 row8">8</th>
      <td id="T_a5791_row8_col0" class="data row8 col0">0.00</td>
      <td id="T_a5791_row8_col1" class="data row8 col1">0.00</td>
      <td id="T_a5791_row8_col2" class="data row8 col2">0.00</td>
      <td id="T_a5791_row8_col3" class="data row8 col3">0.00</td>
      <td id="T_a5791_row8_col4" class="data row8 col4">0.00</td>
      <td id="T_a5791_row8_col5" class="data row8 col5">0.00</td>
      <td id="T_a5791_row8_col6" class="data row8 col6">0.00</td>
      <td id="T_a5791_row8_col7" class="data row8 col7">0.07</td>
      <td id="T_a5791_row8_col8" class="data row8 col8">0.86</td>
      <td id="T_a5791_row8_col9" class="data row8 col9">0.99</td>
      <td id="T_a5791_row8_col10" class="data row8 col10">0.99</td>
      <td id="T_a5791_row8_col11" class="data row8 col11">0.99</td>
      <td id="T_a5791_row8_col12" class="data row8 col12">0.99</td>
      <td id="T_a5791_row8_col13" class="data row8 col13">0.99</td>
      <td id="T_a5791_row8_col14" class="data row8 col14">0.78</td>
      <td id="T_a5791_row8_col15" class="data row8 col15">0.71</td>
      <td id="T_a5791_row8_col16" class="data row8 col16">0.97</td>
      <td id="T_a5791_row8_col17" class="data row8 col17">0.95</td>
      <td id="T_a5791_row8_col18" class="data row8 col18">0.00</td>
      <td id="T_a5791_row8_col19" class="data row8 col19">0.00</td>
      <td id="T_a5791_row8_col20" class="data row8 col20">0.00</td>
      <td id="T_a5791_row8_col21" class="data row8 col21">0.00</td>
      <td id="T_a5791_row8_col22" class="data row8 col22">0.00</td>
      <td id="T_a5791_row8_col23" class="data row8 col23">0.00</td>
      <td id="T_a5791_row8_col24" class="data row8 col24">0.00</td>
      <td id="T_a5791_row8_col25" class="data row8 col25">0.00</td>
      <td id="T_a5791_row8_col26" class="data row8 col26">0.00</td>
      <td id="T_a5791_row8_col27" class="data row8 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row9" class="row_heading level0 row9">9</th>
      <td id="T_a5791_row9_col0" class="data row9 col0">0.00</td>
      <td id="T_a5791_row9_col1" class="data row9 col1">0.00</td>
      <td id="T_a5791_row9_col2" class="data row9 col2">0.00</td>
      <td id="T_a5791_row9_col3" class="data row9 col3">0.00</td>
      <td id="T_a5791_row9_col4" class="data row9 col4">0.00</td>
      <td id="T_a5791_row9_col5" class="data row9 col5">0.00</td>
      <td id="T_a5791_row9_col6" class="data row9 col6">0.00</td>
      <td id="T_a5791_row9_col7" class="data row9 col7">0.00</td>
      <td id="T_a5791_row9_col8" class="data row9 col8">0.31</td>
      <td id="T_a5791_row9_col9" class="data row9 col9">0.61</td>
      <td id="T_a5791_row9_col10" class="data row9 col10">0.42</td>
      <td id="T_a5791_row9_col11" class="data row9 col11">0.99</td>
      <td id="T_a5791_row9_col12" class="data row9 col12">0.99</td>
      <td id="T_a5791_row9_col13" class="data row9 col13">0.80</td>
      <td id="T_a5791_row9_col14" class="data row9 col14">0.04</td>
      <td id="T_a5791_row9_col15" class="data row9 col15">0.00</td>
      <td id="T_a5791_row9_col16" class="data row9 col16">0.17</td>
      <td id="T_a5791_row9_col17" class="data row9 col17">0.60</td>
      <td id="T_a5791_row9_col18" class="data row9 col18">0.00</td>
      <td id="T_a5791_row9_col19" class="data row9 col19">0.00</td>
      <td id="T_a5791_row9_col20" class="data row9 col20">0.00</td>
      <td id="T_a5791_row9_col21" class="data row9 col21">0.00</td>
      <td id="T_a5791_row9_col22" class="data row9 col22">0.00</td>
      <td id="T_a5791_row9_col23" class="data row9 col23">0.00</td>
      <td id="T_a5791_row9_col24" class="data row9 col24">0.00</td>
      <td id="T_a5791_row9_col25" class="data row9 col25">0.00</td>
      <td id="T_a5791_row9_col26" class="data row9 col26">0.00</td>
      <td id="T_a5791_row9_col27" class="data row9 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row10" class="row_heading level0 row10">10</th>
      <td id="T_a5791_row10_col0" class="data row10 col0">0.00</td>
      <td id="T_a5791_row10_col1" class="data row10 col1">0.00</td>
      <td id="T_a5791_row10_col2" class="data row10 col2">0.00</td>
      <td id="T_a5791_row10_col3" class="data row10 col3">0.00</td>
      <td id="T_a5791_row10_col4" class="data row10 col4">0.00</td>
      <td id="T_a5791_row10_col5" class="data row10 col5">0.00</td>
      <td id="T_a5791_row10_col6" class="data row10 col6">0.00</td>
      <td id="T_a5791_row10_col7" class="data row10 col7">0.00</td>
      <td id="T_a5791_row10_col8" class="data row10 col8">0.00</td>
      <td id="T_a5791_row10_col9" class="data row10 col9">0.05</td>
      <td id="T_a5791_row10_col10" class="data row10 col10">0.00</td>
      <td id="T_a5791_row10_col11" class="data row10 col11">0.60</td>
      <td id="T_a5791_row10_col12" class="data row10 col12">0.99</td>
      <td id="T_a5791_row10_col13" class="data row10 col13">0.35</td>
      <td id="T_a5791_row10_col14" class="data row10 col14">0.00</td>
      <td id="T_a5791_row10_col15" class="data row10 col15">0.00</td>
      <td id="T_a5791_row10_col16" class="data row10 col16">0.00</td>
      <td id="T_a5791_row10_col17" class="data row10 col17">0.00</td>
      <td id="T_a5791_row10_col18" class="data row10 col18">0.00</td>
      <td id="T_a5791_row10_col19" class="data row10 col19">0.00</td>
      <td id="T_a5791_row10_col20" class="data row10 col20">0.00</td>
      <td id="T_a5791_row10_col21" class="data row10 col21">0.00</td>
      <td id="T_a5791_row10_col22" class="data row10 col22">0.00</td>
      <td id="T_a5791_row10_col23" class="data row10 col23">0.00</td>
      <td id="T_a5791_row10_col24" class="data row10 col24">0.00</td>
      <td id="T_a5791_row10_col25" class="data row10 col25">0.00</td>
      <td id="T_a5791_row10_col26" class="data row10 col26">0.00</td>
      <td id="T_a5791_row10_col27" class="data row10 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row11" class="row_heading level0 row11">11</th>
      <td id="T_a5791_row11_col0" class="data row11 col0">0.00</td>
      <td id="T_a5791_row11_col1" class="data row11 col1">0.00</td>
      <td id="T_a5791_row11_col2" class="data row11 col2">0.00</td>
      <td id="T_a5791_row11_col3" class="data row11 col3">0.00</td>
      <td id="T_a5791_row11_col4" class="data row11 col4">0.00</td>
      <td id="T_a5791_row11_col5" class="data row11 col5">0.00</td>
      <td id="T_a5791_row11_col6" class="data row11 col6">0.00</td>
      <td id="T_a5791_row11_col7" class="data row11 col7">0.00</td>
      <td id="T_a5791_row11_col8" class="data row11 col8">0.00</td>
      <td id="T_a5791_row11_col9" class="data row11 col9">0.00</td>
      <td id="T_a5791_row11_col10" class="data row11 col10">0.00</td>
      <td id="T_a5791_row11_col11" class="data row11 col11">0.55</td>
      <td id="T_a5791_row11_col12" class="data row11 col12">0.99</td>
      <td id="T_a5791_row11_col13" class="data row11 col13">0.75</td>
      <td id="T_a5791_row11_col14" class="data row11 col14">0.01</td>
      <td id="T_a5791_row11_col15" class="data row11 col15">0.00</td>
      <td id="T_a5791_row11_col16" class="data row11 col16">0.00</td>
      <td id="T_a5791_row11_col17" class="data row11 col17">0.00</td>
      <td id="T_a5791_row11_col18" class="data row11 col18">0.00</td>
      <td id="T_a5791_row11_col19" class="data row11 col19">0.00</td>
      <td id="T_a5791_row11_col20" class="data row11 col20">0.00</td>
      <td id="T_a5791_row11_col21" class="data row11 col21">0.00</td>
      <td id="T_a5791_row11_col22" class="data row11 col22">0.00</td>
      <td id="T_a5791_row11_col23" class="data row11 col23">0.00</td>
      <td id="T_a5791_row11_col24" class="data row11 col24">0.00</td>
      <td id="T_a5791_row11_col25" class="data row11 col25">0.00</td>
      <td id="T_a5791_row11_col26" class="data row11 col26">0.00</td>
      <td id="T_a5791_row11_col27" class="data row11 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row12" class="row_heading level0 row12">12</th>
      <td id="T_a5791_row12_col0" class="data row12 col0">0.00</td>
      <td id="T_a5791_row12_col1" class="data row12 col1">0.00</td>
      <td id="T_a5791_row12_col2" class="data row12 col2">0.00</td>
      <td id="T_a5791_row12_col3" class="data row12 col3">0.00</td>
      <td id="T_a5791_row12_col4" class="data row12 col4">0.00</td>
      <td id="T_a5791_row12_col5" class="data row12 col5">0.00</td>
      <td id="T_a5791_row12_col6" class="data row12 col6">0.00</td>
      <td id="T_a5791_row12_col7" class="data row12 col7">0.00</td>
      <td id="T_a5791_row12_col8" class="data row12 col8">0.00</td>
      <td id="T_a5791_row12_col9" class="data row12 col9">0.00</td>
      <td id="T_a5791_row12_col10" class="data row12 col10">0.00</td>
      <td id="T_a5791_row12_col11" class="data row12 col11">0.04</td>
      <td id="T_a5791_row12_col12" class="data row12 col12">0.75</td>
      <td id="T_a5791_row12_col13" class="data row12 col13">0.99</td>
      <td id="T_a5791_row12_col14" class="data row12 col14">0.27</td>
      <td id="T_a5791_row12_col15" class="data row12 col15">0.00</td>
      <td id="T_a5791_row12_col16" class="data row12 col16">0.00</td>
      <td id="T_a5791_row12_col17" class="data row12 col17">0.00</td>
      <td id="T_a5791_row12_col18" class="data row12 col18">0.00</td>
      <td id="T_a5791_row12_col19" class="data row12 col19">0.00</td>
      <td id="T_a5791_row12_col20" class="data row12 col20">0.00</td>
      <td id="T_a5791_row12_col21" class="data row12 col21">0.00</td>
      <td id="T_a5791_row12_col22" class="data row12 col22">0.00</td>
      <td id="T_a5791_row12_col23" class="data row12 col23">0.00</td>
      <td id="T_a5791_row12_col24" class="data row12 col24">0.00</td>
      <td id="T_a5791_row12_col25" class="data row12 col25">0.00</td>
      <td id="T_a5791_row12_col26" class="data row12 col26">0.00</td>
      <td id="T_a5791_row12_col27" class="data row12 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row13" class="row_heading level0 row13">13</th>
      <td id="T_a5791_row13_col0" class="data row13 col0">0.00</td>
      <td id="T_a5791_row13_col1" class="data row13 col1">0.00</td>
      <td id="T_a5791_row13_col2" class="data row13 col2">0.00</td>
      <td id="T_a5791_row13_col3" class="data row13 col3">0.00</td>
      <td id="T_a5791_row13_col4" class="data row13 col4">0.00</td>
      <td id="T_a5791_row13_col5" class="data row13 col5">0.00</td>
      <td id="T_a5791_row13_col6" class="data row13 col6">0.00</td>
      <td id="T_a5791_row13_col7" class="data row13 col7">0.00</td>
      <td id="T_a5791_row13_col8" class="data row13 col8">0.00</td>
      <td id="T_a5791_row13_col9" class="data row13 col9">0.00</td>
      <td id="T_a5791_row13_col10" class="data row13 col10">0.00</td>
      <td id="T_a5791_row13_col11" class="data row13 col11">0.00</td>
      <td id="T_a5791_row13_col12" class="data row13 col12">0.14</td>
      <td id="T_a5791_row13_col13" class="data row13 col13">0.95</td>
      <td id="T_a5791_row13_col14" class="data row13 col14">0.88</td>
      <td id="T_a5791_row13_col15" class="data row13 col15">0.63</td>
      <td id="T_a5791_row13_col16" class="data row13 col16">0.42</td>
      <td id="T_a5791_row13_col17" class="data row13 col17">0.00</td>
      <td id="T_a5791_row13_col18" class="data row13 col18">0.00</td>
      <td id="T_a5791_row13_col19" class="data row13 col19">0.00</td>
      <td id="T_a5791_row13_col20" class="data row13 col20">0.00</td>
      <td id="T_a5791_row13_col21" class="data row13 col21">0.00</td>
      <td id="T_a5791_row13_col22" class="data row13 col22">0.00</td>
      <td id="T_a5791_row13_col23" class="data row13 col23">0.00</td>
      <td id="T_a5791_row13_col24" class="data row13 col24">0.00</td>
      <td id="T_a5791_row13_col25" class="data row13 col25">0.00</td>
      <td id="T_a5791_row13_col26" class="data row13 col26">0.00</td>
      <td id="T_a5791_row13_col27" class="data row13 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row14" class="row_heading level0 row14">14</th>
      <td id="T_a5791_row14_col0" class="data row14 col0">0.00</td>
      <td id="T_a5791_row14_col1" class="data row14 col1">0.00</td>
      <td id="T_a5791_row14_col2" class="data row14 col2">0.00</td>
      <td id="T_a5791_row14_col3" class="data row14 col3">0.00</td>
      <td id="T_a5791_row14_col4" class="data row14 col4">0.00</td>
      <td id="T_a5791_row14_col5" class="data row14 col5">0.00</td>
      <td id="T_a5791_row14_col6" class="data row14 col6">0.00</td>
      <td id="T_a5791_row14_col7" class="data row14 col7">0.00</td>
      <td id="T_a5791_row14_col8" class="data row14 col8">0.00</td>
      <td id="T_a5791_row14_col9" class="data row14 col9">0.00</td>
      <td id="T_a5791_row14_col10" class="data row14 col10">0.00</td>
      <td id="T_a5791_row14_col11" class="data row14 col11">0.00</td>
      <td id="T_a5791_row14_col12" class="data row14 col12">0.00</td>
      <td id="T_a5791_row14_col13" class="data row14 col13">0.32</td>
      <td id="T_a5791_row14_col14" class="data row14 col14">0.94</td>
      <td id="T_a5791_row14_col15" class="data row14 col15">0.99</td>
      <td id="T_a5791_row14_col16" class="data row14 col16">0.99</td>
      <td id="T_a5791_row14_col17" class="data row14 col17">0.47</td>
      <td id="T_a5791_row14_col18" class="data row14 col18">0.10</td>
      <td id="T_a5791_row14_col19" class="data row14 col19">0.00</td>
      <td id="T_a5791_row14_col20" class="data row14 col20">0.00</td>
      <td id="T_a5791_row14_col21" class="data row14 col21">0.00</td>
      <td id="T_a5791_row14_col22" class="data row14 col22">0.00</td>
      <td id="T_a5791_row14_col23" class="data row14 col23">0.00</td>
      <td id="T_a5791_row14_col24" class="data row14 col24">0.00</td>
      <td id="T_a5791_row14_col25" class="data row14 col25">0.00</td>
      <td id="T_a5791_row14_col26" class="data row14 col26">0.00</td>
      <td id="T_a5791_row14_col27" class="data row14 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row15" class="row_heading level0 row15">15</th>
      <td id="T_a5791_row15_col0" class="data row15 col0">0.00</td>
      <td id="T_a5791_row15_col1" class="data row15 col1">0.00</td>
      <td id="T_a5791_row15_col2" class="data row15 col2">0.00</td>
      <td id="T_a5791_row15_col3" class="data row15 col3">0.00</td>
      <td id="T_a5791_row15_col4" class="data row15 col4">0.00</td>
      <td id="T_a5791_row15_col5" class="data row15 col5">0.00</td>
      <td id="T_a5791_row15_col6" class="data row15 col6">0.00</td>
      <td id="T_a5791_row15_col7" class="data row15 col7">0.00</td>
      <td id="T_a5791_row15_col8" class="data row15 col8">0.00</td>
      <td id="T_a5791_row15_col9" class="data row15 col9">0.00</td>
      <td id="T_a5791_row15_col10" class="data row15 col10">0.00</td>
      <td id="T_a5791_row15_col11" class="data row15 col11">0.00</td>
      <td id="T_a5791_row15_col12" class="data row15 col12">0.00</td>
      <td id="T_a5791_row15_col13" class="data row15 col13">0.00</td>
      <td id="T_a5791_row15_col14" class="data row15 col14">0.18</td>
      <td id="T_a5791_row15_col15" class="data row15 col15">0.73</td>
      <td id="T_a5791_row15_col16" class="data row15 col16">0.99</td>
      <td id="T_a5791_row15_col17" class="data row15 col17">0.99</td>
      <td id="T_a5791_row15_col18" class="data row15 col18">0.59</td>
      <td id="T_a5791_row15_col19" class="data row15 col19">0.11</td>
      <td id="T_a5791_row15_col20" class="data row15 col20">0.00</td>
      <td id="T_a5791_row15_col21" class="data row15 col21">0.00</td>
      <td id="T_a5791_row15_col22" class="data row15 col22">0.00</td>
      <td id="T_a5791_row15_col23" class="data row15 col23">0.00</td>
      <td id="T_a5791_row15_col24" class="data row15 col24">0.00</td>
      <td id="T_a5791_row15_col25" class="data row15 col25">0.00</td>
      <td id="T_a5791_row15_col26" class="data row15 col26">0.00</td>
      <td id="T_a5791_row15_col27" class="data row15 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row16" class="row_heading level0 row16">16</th>
      <td id="T_a5791_row16_col0" class="data row16 col0">0.00</td>
      <td id="T_a5791_row16_col1" class="data row16 col1">0.00</td>
      <td id="T_a5791_row16_col2" class="data row16 col2">0.00</td>
      <td id="T_a5791_row16_col3" class="data row16 col3">0.00</td>
      <td id="T_a5791_row16_col4" class="data row16 col4">0.00</td>
      <td id="T_a5791_row16_col5" class="data row16 col5">0.00</td>
      <td id="T_a5791_row16_col6" class="data row16 col6">0.00</td>
      <td id="T_a5791_row16_col7" class="data row16 col7">0.00</td>
      <td id="T_a5791_row16_col8" class="data row16 col8">0.00</td>
      <td id="T_a5791_row16_col9" class="data row16 col9">0.00</td>
      <td id="T_a5791_row16_col10" class="data row16 col10">0.00</td>
      <td id="T_a5791_row16_col11" class="data row16 col11">0.00</td>
      <td id="T_a5791_row16_col12" class="data row16 col12">0.00</td>
      <td id="T_a5791_row16_col13" class="data row16 col13">0.00</td>
      <td id="T_a5791_row16_col14" class="data row16 col14">0.00</td>
      <td id="T_a5791_row16_col15" class="data row16 col15">0.06</td>
      <td id="T_a5791_row16_col16" class="data row16 col16">0.36</td>
      <td id="T_a5791_row16_col17" class="data row16 col17">0.99</td>
      <td id="T_a5791_row16_col18" class="data row16 col18">0.99</td>
      <td id="T_a5791_row16_col19" class="data row16 col19">0.73</td>
      <td id="T_a5791_row16_col20" class="data row16 col20">0.00</td>
      <td id="T_a5791_row16_col21" class="data row16 col21">0.00</td>
      <td id="T_a5791_row16_col22" class="data row16 col22">0.00</td>
      <td id="T_a5791_row16_col23" class="data row16 col23">0.00</td>
      <td id="T_a5791_row16_col24" class="data row16 col24">0.00</td>
      <td id="T_a5791_row16_col25" class="data row16 col25">0.00</td>
      <td id="T_a5791_row16_col26" class="data row16 col26">0.00</td>
      <td id="T_a5791_row16_col27" class="data row16 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row17" class="row_heading level0 row17">17</th>
      <td id="T_a5791_row17_col0" class="data row17 col0">0.00</td>
      <td id="T_a5791_row17_col1" class="data row17 col1">0.00</td>
      <td id="T_a5791_row17_col2" class="data row17 col2">0.00</td>
      <td id="T_a5791_row17_col3" class="data row17 col3">0.00</td>
      <td id="T_a5791_row17_col4" class="data row17 col4">0.00</td>
      <td id="T_a5791_row17_col5" class="data row17 col5">0.00</td>
      <td id="T_a5791_row17_col6" class="data row17 col6">0.00</td>
      <td id="T_a5791_row17_col7" class="data row17 col7">0.00</td>
      <td id="T_a5791_row17_col8" class="data row17 col8">0.00</td>
      <td id="T_a5791_row17_col9" class="data row17 col9">0.00</td>
      <td id="T_a5791_row17_col10" class="data row17 col10">0.00</td>
      <td id="T_a5791_row17_col11" class="data row17 col11">0.00</td>
      <td id="T_a5791_row17_col12" class="data row17 col12">0.00</td>
      <td id="T_a5791_row17_col13" class="data row17 col13">0.00</td>
      <td id="T_a5791_row17_col14" class="data row17 col14">0.00</td>
      <td id="T_a5791_row17_col15" class="data row17 col15">0.00</td>
      <td id="T_a5791_row17_col16" class="data row17 col16">0.00</td>
      <td id="T_a5791_row17_col17" class="data row17 col17">0.98</td>
      <td id="T_a5791_row17_col18" class="data row17 col18">0.99</td>
      <td id="T_a5791_row17_col19" class="data row17 col19">0.98</td>
      <td id="T_a5791_row17_col20" class="data row17 col20">0.25</td>
      <td id="T_a5791_row17_col21" class="data row17 col21">0.00</td>
      <td id="T_a5791_row17_col22" class="data row17 col22">0.00</td>
      <td id="T_a5791_row17_col23" class="data row17 col23">0.00</td>
      <td id="T_a5791_row17_col24" class="data row17 col24">0.00</td>
      <td id="T_a5791_row17_col25" class="data row17 col25">0.00</td>
      <td id="T_a5791_row17_col26" class="data row17 col26">0.00</td>
      <td id="T_a5791_row17_col27" class="data row17 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row18" class="row_heading level0 row18">18</th>
      <td id="T_a5791_row18_col0" class="data row18 col0">0.00</td>
      <td id="T_a5791_row18_col1" class="data row18 col1">0.00</td>
      <td id="T_a5791_row18_col2" class="data row18 col2">0.00</td>
      <td id="T_a5791_row18_col3" class="data row18 col3">0.00</td>
      <td id="T_a5791_row18_col4" class="data row18 col4">0.00</td>
      <td id="T_a5791_row18_col5" class="data row18 col5">0.00</td>
      <td id="T_a5791_row18_col6" class="data row18 col6">0.00</td>
      <td id="T_a5791_row18_col7" class="data row18 col7">0.00</td>
      <td id="T_a5791_row18_col8" class="data row18 col8">0.00</td>
      <td id="T_a5791_row18_col9" class="data row18 col9">0.00</td>
      <td id="T_a5791_row18_col10" class="data row18 col10">0.00</td>
      <td id="T_a5791_row18_col11" class="data row18 col11">0.00</td>
      <td id="T_a5791_row18_col12" class="data row18 col12">0.00</td>
      <td id="T_a5791_row18_col13" class="data row18 col13">0.00</td>
      <td id="T_a5791_row18_col14" class="data row18 col14">0.18</td>
      <td id="T_a5791_row18_col15" class="data row18 col15">0.51</td>
      <td id="T_a5791_row18_col16" class="data row18 col16">0.72</td>
      <td id="T_a5791_row18_col17" class="data row18 col17">0.99</td>
      <td id="T_a5791_row18_col18" class="data row18 col18">0.99</td>
      <td id="T_a5791_row18_col19" class="data row18 col19">0.81</td>
      <td id="T_a5791_row18_col20" class="data row18 col20">0.01</td>
      <td id="T_a5791_row18_col21" class="data row18 col21">0.00</td>
      <td id="T_a5791_row18_col22" class="data row18 col22">0.00</td>
      <td id="T_a5791_row18_col23" class="data row18 col23">0.00</td>
      <td id="T_a5791_row18_col24" class="data row18 col24">0.00</td>
      <td id="T_a5791_row18_col25" class="data row18 col25">0.00</td>
      <td id="T_a5791_row18_col26" class="data row18 col26">0.00</td>
      <td id="T_a5791_row18_col27" class="data row18 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row19" class="row_heading level0 row19">19</th>
      <td id="T_a5791_row19_col0" class="data row19 col0">0.00</td>
      <td id="T_a5791_row19_col1" class="data row19 col1">0.00</td>
      <td id="T_a5791_row19_col2" class="data row19 col2">0.00</td>
      <td id="T_a5791_row19_col3" class="data row19 col3">0.00</td>
      <td id="T_a5791_row19_col4" class="data row19 col4">0.00</td>
      <td id="T_a5791_row19_col5" class="data row19 col5">0.00</td>
      <td id="T_a5791_row19_col6" class="data row19 col6">0.00</td>
      <td id="T_a5791_row19_col7" class="data row19 col7">0.00</td>
      <td id="T_a5791_row19_col8" class="data row19 col8">0.00</td>
      <td id="T_a5791_row19_col9" class="data row19 col9">0.00</td>
      <td id="T_a5791_row19_col10" class="data row19 col10">0.00</td>
      <td id="T_a5791_row19_col11" class="data row19 col11">0.00</td>
      <td id="T_a5791_row19_col12" class="data row19 col12">0.15</td>
      <td id="T_a5791_row19_col13" class="data row19 col13">0.58</td>
      <td id="T_a5791_row19_col14" class="data row19 col14">0.90</td>
      <td id="T_a5791_row19_col15" class="data row19 col15">0.99</td>
      <td id="T_a5791_row19_col16" class="data row19 col16">0.99</td>
      <td id="T_a5791_row19_col17" class="data row19 col17">0.99</td>
      <td id="T_a5791_row19_col18" class="data row19 col18">0.98</td>
      <td id="T_a5791_row19_col19" class="data row19 col19">0.71</td>
      <td id="T_a5791_row19_col20" class="data row19 col20">0.00</td>
      <td id="T_a5791_row19_col21" class="data row19 col21">0.00</td>
      <td id="T_a5791_row19_col22" class="data row19 col22">0.00</td>
      <td id="T_a5791_row19_col23" class="data row19 col23">0.00</td>
      <td id="T_a5791_row19_col24" class="data row19 col24">0.00</td>
      <td id="T_a5791_row19_col25" class="data row19 col25">0.00</td>
      <td id="T_a5791_row19_col26" class="data row19 col26">0.00</td>
      <td id="T_a5791_row19_col27" class="data row19 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row20" class="row_heading level0 row20">20</th>
      <td id="T_a5791_row20_col0" class="data row20 col0">0.00</td>
      <td id="T_a5791_row20_col1" class="data row20 col1">0.00</td>
      <td id="T_a5791_row20_col2" class="data row20 col2">0.00</td>
      <td id="T_a5791_row20_col3" class="data row20 col3">0.00</td>
      <td id="T_a5791_row20_col4" class="data row20 col4">0.00</td>
      <td id="T_a5791_row20_col5" class="data row20 col5">0.00</td>
      <td id="T_a5791_row20_col6" class="data row20 col6">0.00</td>
      <td id="T_a5791_row20_col7" class="data row20 col7">0.00</td>
      <td id="T_a5791_row20_col8" class="data row20 col8">0.00</td>
      <td id="T_a5791_row20_col9" class="data row20 col9">0.00</td>
      <td id="T_a5791_row20_col10" class="data row20 col10">0.09</td>
      <td id="T_a5791_row20_col11" class="data row20 col11">0.45</td>
      <td id="T_a5791_row20_col12" class="data row20 col12">0.87</td>
      <td id="T_a5791_row20_col13" class="data row20 col13">0.99</td>
      <td id="T_a5791_row20_col14" class="data row20 col14">0.99</td>
      <td id="T_a5791_row20_col15" class="data row20 col15">0.99</td>
      <td id="T_a5791_row20_col16" class="data row20 col16">0.99</td>
      <td id="T_a5791_row20_col17" class="data row20 col17">0.79</td>
      <td id="T_a5791_row20_col18" class="data row20 col18">0.31</td>
      <td id="T_a5791_row20_col19" class="data row20 col19">0.00</td>
      <td id="T_a5791_row20_col20" class="data row20 col20">0.00</td>
      <td id="T_a5791_row20_col21" class="data row20 col21">0.00</td>
      <td id="T_a5791_row20_col22" class="data row20 col22">0.00</td>
      <td id="T_a5791_row20_col23" class="data row20 col23">0.00</td>
      <td id="T_a5791_row20_col24" class="data row20 col24">0.00</td>
      <td id="T_a5791_row20_col25" class="data row20 col25">0.00</td>
      <td id="T_a5791_row20_col26" class="data row20 col26">0.00</td>
      <td id="T_a5791_row20_col27" class="data row20 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row21" class="row_heading level0 row21">21</th>
      <td id="T_a5791_row21_col0" class="data row21 col0">0.00</td>
      <td id="T_a5791_row21_col1" class="data row21 col1">0.00</td>
      <td id="T_a5791_row21_col2" class="data row21 col2">0.00</td>
      <td id="T_a5791_row21_col3" class="data row21 col3">0.00</td>
      <td id="T_a5791_row21_col4" class="data row21 col4">0.00</td>
      <td id="T_a5791_row21_col5" class="data row21 col5">0.00</td>
      <td id="T_a5791_row21_col6" class="data row21 col6">0.00</td>
      <td id="T_a5791_row21_col7" class="data row21 col7">0.00</td>
      <td id="T_a5791_row21_col8" class="data row21 col8">0.09</td>
      <td id="T_a5791_row21_col9" class="data row21 col9">0.26</td>
      <td id="T_a5791_row21_col10" class="data row21 col10">0.84</td>
      <td id="T_a5791_row21_col11" class="data row21 col11">0.99</td>
      <td id="T_a5791_row21_col12" class="data row21 col12">0.99</td>
      <td id="T_a5791_row21_col13" class="data row21 col13">0.99</td>
      <td id="T_a5791_row21_col14" class="data row21 col14">0.99</td>
      <td id="T_a5791_row21_col15" class="data row21 col15">0.78</td>
      <td id="T_a5791_row21_col16" class="data row21 col16">0.32</td>
      <td id="T_a5791_row21_col17" class="data row21 col17">0.01</td>
      <td id="T_a5791_row21_col18" class="data row21 col18">0.00</td>
      <td id="T_a5791_row21_col19" class="data row21 col19">0.00</td>
      <td id="T_a5791_row21_col20" class="data row21 col20">0.00</td>
      <td id="T_a5791_row21_col21" class="data row21 col21">0.00</td>
      <td id="T_a5791_row21_col22" class="data row21 col22">0.00</td>
      <td id="T_a5791_row21_col23" class="data row21 col23">0.00</td>
      <td id="T_a5791_row21_col24" class="data row21 col24">0.00</td>
      <td id="T_a5791_row21_col25" class="data row21 col25">0.00</td>
      <td id="T_a5791_row21_col26" class="data row21 col26">0.00</td>
      <td id="T_a5791_row21_col27" class="data row21 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row22" class="row_heading level0 row22">22</th>
      <td id="T_a5791_row22_col0" class="data row22 col0">0.00</td>
      <td id="T_a5791_row22_col1" class="data row22 col1">0.00</td>
      <td id="T_a5791_row22_col2" class="data row22 col2">0.00</td>
      <td id="T_a5791_row22_col3" class="data row22 col3">0.00</td>
      <td id="T_a5791_row22_col4" class="data row22 col4">0.00</td>
      <td id="T_a5791_row22_col5" class="data row22 col5">0.00</td>
      <td id="T_a5791_row22_col6" class="data row22 col6">0.07</td>
      <td id="T_a5791_row22_col7" class="data row22 col7">0.67</td>
      <td id="T_a5791_row22_col8" class="data row22 col8">0.86</td>
      <td id="T_a5791_row22_col9" class="data row22 col9">0.99</td>
      <td id="T_a5791_row22_col10" class="data row22 col10">0.99</td>
      <td id="T_a5791_row22_col11" class="data row22 col11">0.99</td>
      <td id="T_a5791_row22_col12" class="data row22 col12">0.99</td>
      <td id="T_a5791_row22_col13" class="data row22 col13">0.76</td>
      <td id="T_a5791_row22_col14" class="data row22 col14">0.31</td>
      <td id="T_a5791_row22_col15" class="data row22 col15">0.04</td>
      <td id="T_a5791_row22_col16" class="data row22 col16">0.00</td>
      <td id="T_a5791_row22_col17" class="data row22 col17">0.00</td>
      <td id="T_a5791_row22_col18" class="data row22 col18">0.00</td>
      <td id="T_a5791_row22_col19" class="data row22 col19">0.00</td>
      <td id="T_a5791_row22_col20" class="data row22 col20">0.00</td>
      <td id="T_a5791_row22_col21" class="data row22 col21">0.00</td>
      <td id="T_a5791_row22_col22" class="data row22 col22">0.00</td>
      <td id="T_a5791_row22_col23" class="data row22 col23">0.00</td>
      <td id="T_a5791_row22_col24" class="data row22 col24">0.00</td>
      <td id="T_a5791_row22_col25" class="data row22 col25">0.00</td>
      <td id="T_a5791_row22_col26" class="data row22 col26">0.00</td>
      <td id="T_a5791_row22_col27" class="data row22 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row23" class="row_heading level0 row23">23</th>
      <td id="T_a5791_row23_col0" class="data row23 col0">0.00</td>
      <td id="T_a5791_row23_col1" class="data row23 col1">0.00</td>
      <td id="T_a5791_row23_col2" class="data row23 col2">0.00</td>
      <td id="T_a5791_row23_col3" class="data row23 col3">0.00</td>
      <td id="T_a5791_row23_col4" class="data row23 col4">0.22</td>
      <td id="T_a5791_row23_col5" class="data row23 col5">0.67</td>
      <td id="T_a5791_row23_col6" class="data row23 col6">0.89</td>
      <td id="T_a5791_row23_col7" class="data row23 col7">0.99</td>
      <td id="T_a5791_row23_col8" class="data row23 col8">0.99</td>
      <td id="T_a5791_row23_col9" class="data row23 col9">0.99</td>
      <td id="T_a5791_row23_col10" class="data row23 col10">0.99</td>
      <td id="T_a5791_row23_col11" class="data row23 col11">0.96</td>
      <td id="T_a5791_row23_col12" class="data row23 col12">0.52</td>
      <td id="T_a5791_row23_col13" class="data row23 col13">0.04</td>
      <td id="T_a5791_row23_col14" class="data row23 col14">0.00</td>
      <td id="T_a5791_row23_col15" class="data row23 col15">0.00</td>
      <td id="T_a5791_row23_col16" class="data row23 col16">0.00</td>
      <td id="T_a5791_row23_col17" class="data row23 col17">0.00</td>
      <td id="T_a5791_row23_col18" class="data row23 col18">0.00</td>
      <td id="T_a5791_row23_col19" class="data row23 col19">0.00</td>
      <td id="T_a5791_row23_col20" class="data row23 col20">0.00</td>
      <td id="T_a5791_row23_col21" class="data row23 col21">0.00</td>
      <td id="T_a5791_row23_col22" class="data row23 col22">0.00</td>
      <td id="T_a5791_row23_col23" class="data row23 col23">0.00</td>
      <td id="T_a5791_row23_col24" class="data row23 col24">0.00</td>
      <td id="T_a5791_row23_col25" class="data row23 col25">0.00</td>
      <td id="T_a5791_row23_col26" class="data row23 col26">0.00</td>
      <td id="T_a5791_row23_col27" class="data row23 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row24" class="row_heading level0 row24">24</th>
      <td id="T_a5791_row24_col0" class="data row24 col0">0.00</td>
      <td id="T_a5791_row24_col1" class="data row24 col1">0.00</td>
      <td id="T_a5791_row24_col2" class="data row24 col2">0.00</td>
      <td id="T_a5791_row24_col3" class="data row24 col3">0.00</td>
      <td id="T_a5791_row24_col4" class="data row24 col4">0.53</td>
      <td id="T_a5791_row24_col5" class="data row24 col5">0.99</td>
      <td id="T_a5791_row24_col6" class="data row24 col6">0.99</td>
      <td id="T_a5791_row24_col7" class="data row24 col7">0.99</td>
      <td id="T_a5791_row24_col8" class="data row24 col8">0.83</td>
      <td id="T_a5791_row24_col9" class="data row24 col9">0.53</td>
      <td id="T_a5791_row24_col10" class="data row24 col10">0.52</td>
      <td id="T_a5791_row24_col11" class="data row24 col11">0.06</td>
      <td id="T_a5791_row24_col12" class="data row24 col12">0.00</td>
      <td id="T_a5791_row24_col13" class="data row24 col13">0.00</td>
      <td id="T_a5791_row24_col14" class="data row24 col14">0.00</td>
      <td id="T_a5791_row24_col15" class="data row24 col15">0.00</td>
      <td id="T_a5791_row24_col16" class="data row24 col16">0.00</td>
      <td id="T_a5791_row24_col17" class="data row24 col17">0.00</td>
      <td id="T_a5791_row24_col18" class="data row24 col18">0.00</td>
      <td id="T_a5791_row24_col19" class="data row24 col19">0.00</td>
      <td id="T_a5791_row24_col20" class="data row24 col20">0.00</td>
      <td id="T_a5791_row24_col21" class="data row24 col21">0.00</td>
      <td id="T_a5791_row24_col22" class="data row24 col22">0.00</td>
      <td id="T_a5791_row24_col23" class="data row24 col23">0.00</td>
      <td id="T_a5791_row24_col24" class="data row24 col24">0.00</td>
      <td id="T_a5791_row24_col25" class="data row24 col25">0.00</td>
      <td id="T_a5791_row24_col26" class="data row24 col26">0.00</td>
      <td id="T_a5791_row24_col27" class="data row24 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row25" class="row_heading level0 row25">25</th>
      <td id="T_a5791_row25_col0" class="data row25 col0">0.00</td>
      <td id="T_a5791_row25_col1" class="data row25 col1">0.00</td>
      <td id="T_a5791_row25_col2" class="data row25 col2">0.00</td>
      <td id="T_a5791_row25_col3" class="data row25 col3">0.00</td>
      <td id="T_a5791_row25_col4" class="data row25 col4">0.00</td>
      <td id="T_a5791_row25_col5" class="data row25 col5">0.00</td>
      <td id="T_a5791_row25_col6" class="data row25 col6">0.00</td>
      <td id="T_a5791_row25_col7" class="data row25 col7">0.00</td>
      <td id="T_a5791_row25_col8" class="data row25 col8">0.00</td>
      <td id="T_a5791_row25_col9" class="data row25 col9">0.00</td>
      <td id="T_a5791_row25_col10" class="data row25 col10">0.00</td>
      <td id="T_a5791_row25_col11" class="data row25 col11">0.00</td>
      <td id="T_a5791_row25_col12" class="data row25 col12">0.00</td>
      <td id="T_a5791_row25_col13" class="data row25 col13">0.00</td>
      <td id="T_a5791_row25_col14" class="data row25 col14">0.00</td>
      <td id="T_a5791_row25_col15" class="data row25 col15">0.00</td>
      <td id="T_a5791_row25_col16" class="data row25 col16">0.00</td>
      <td id="T_a5791_row25_col17" class="data row25 col17">0.00</td>
      <td id="T_a5791_row25_col18" class="data row25 col18">0.00</td>
      <td id="T_a5791_row25_col19" class="data row25 col19">0.00</td>
      <td id="T_a5791_row25_col20" class="data row25 col20">0.00</td>
      <td id="T_a5791_row25_col21" class="data row25 col21">0.00</td>
      <td id="T_a5791_row25_col22" class="data row25 col22">0.00</td>
      <td id="T_a5791_row25_col23" class="data row25 col23">0.00</td>
      <td id="T_a5791_row25_col24" class="data row25 col24">0.00</td>
      <td id="T_a5791_row25_col25" class="data row25 col25">0.00</td>
      <td id="T_a5791_row25_col26" class="data row25 col26">0.00</td>
      <td id="T_a5791_row25_col27" class="data row25 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row26" class="row_heading level0 row26">26</th>
      <td id="T_a5791_row26_col0" class="data row26 col0">0.00</td>
      <td id="T_a5791_row26_col1" class="data row26 col1">0.00</td>
      <td id="T_a5791_row26_col2" class="data row26 col2">0.00</td>
      <td id="T_a5791_row26_col3" class="data row26 col3">0.00</td>
      <td id="T_a5791_row26_col4" class="data row26 col4">0.00</td>
      <td id="T_a5791_row26_col5" class="data row26 col5">0.00</td>
      <td id="T_a5791_row26_col6" class="data row26 col6">0.00</td>
      <td id="T_a5791_row26_col7" class="data row26 col7">0.00</td>
      <td id="T_a5791_row26_col8" class="data row26 col8">0.00</td>
      <td id="T_a5791_row26_col9" class="data row26 col9">0.00</td>
      <td id="T_a5791_row26_col10" class="data row26 col10">0.00</td>
      <td id="T_a5791_row26_col11" class="data row26 col11">0.00</td>
      <td id="T_a5791_row26_col12" class="data row26 col12">0.00</td>
      <td id="T_a5791_row26_col13" class="data row26 col13">0.00</td>
      <td id="T_a5791_row26_col14" class="data row26 col14">0.00</td>
      <td id="T_a5791_row26_col15" class="data row26 col15">0.00</td>
      <td id="T_a5791_row26_col16" class="data row26 col16">0.00</td>
      <td id="T_a5791_row26_col17" class="data row26 col17">0.00</td>
      <td id="T_a5791_row26_col18" class="data row26 col18">0.00</td>
      <td id="T_a5791_row26_col19" class="data row26 col19">0.00</td>
      <td id="T_a5791_row26_col20" class="data row26 col20">0.00</td>
      <td id="T_a5791_row26_col21" class="data row26 col21">0.00</td>
      <td id="T_a5791_row26_col22" class="data row26 col22">0.00</td>
      <td id="T_a5791_row26_col23" class="data row26 col23">0.00</td>
      <td id="T_a5791_row26_col24" class="data row26 col24">0.00</td>
      <td id="T_a5791_row26_col25" class="data row26 col25">0.00</td>
      <td id="T_a5791_row26_col26" class="data row26 col26">0.00</td>
      <td id="T_a5791_row26_col27" class="data row26 col27">0.00</td>
    </tr>
    <tr>
      <th id="T_a5791_level0_row27" class="row_heading level0 row27">27</th>
      <td id="T_a5791_row27_col0" class="data row27 col0">0.00</td>
      <td id="T_a5791_row27_col1" class="data row27 col1">0.00</td>
      <td id="T_a5791_row27_col2" class="data row27 col2">0.00</td>
      <td id="T_a5791_row27_col3" class="data row27 col3">0.00</td>
      <td id="T_a5791_row27_col4" class="data row27 col4">0.00</td>
      <td id="T_a5791_row27_col5" class="data row27 col5">0.00</td>
      <td id="T_a5791_row27_col6" class="data row27 col6">0.00</td>
      <td id="T_a5791_row27_col7" class="data row27 col7">0.00</td>
      <td id="T_a5791_row27_col8" class="data row27 col8">0.00</td>
      <td id="T_a5791_row27_col9" class="data row27 col9">0.00</td>
      <td id="T_a5791_row27_col10" class="data row27 col10">0.00</td>
      <td id="T_a5791_row27_col11" class="data row27 col11">0.00</td>
      <td id="T_a5791_row27_col12" class="data row27 col12">0.00</td>
      <td id="T_a5791_row27_col13" class="data row27 col13">0.00</td>
      <td id="T_a5791_row27_col14" class="data row27 col14">0.00</td>
      <td id="T_a5791_row27_col15" class="data row27 col15">0.00</td>
      <td id="T_a5791_row27_col16" class="data row27 col16">0.00</td>
      <td id="T_a5791_row27_col17" class="data row27 col17">0.00</td>
      <td id="T_a5791_row27_col18" class="data row27 col18">0.00</td>
      <td id="T_a5791_row27_col19" class="data row27 col19">0.00</td>
      <td id="T_a5791_row27_col20" class="data row27 col20">0.00</td>
      <td id="T_a5791_row27_col21" class="data row27 col21">0.00</td>
      <td id="T_a5791_row27_col22" class="data row27 col22">0.00</td>
      <td id="T_a5791_row27_col23" class="data row27 col23">0.00</td>
      <td id="T_a5791_row27_col24" class="data row27 col24">0.00</td>
      <td id="T_a5791_row27_col25" class="data row27 col25">0.00</td>
      <td id="T_a5791_row27_col26" class="data row27 col26">0.00</td>
      <td id="T_a5791_row27_col27" class="data row27 col27">0.00</td>
    </tr>
  </tbody>
</table>
</div>
</div>
<p>Let’s apply the same transformation to both datasets:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.308509Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.308042Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.312821Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.312107Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.308477Z&quot;}" data-trusted="true" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the transforms</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor()</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>data_train.transform <span class="op">=</span> transform</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>data_test.transform <span class="op">=</span> transform</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="prepare-dataset-for-training-create-dataloaders" class="level2">
<h2 class="anchored" data-anchor-id="prepare-dataset-for-training-create-dataloaders">Prepare dataset for training: Create dataloaders</h2>
<p>Previously we have downloaded two datasets: training and testing. To be able to deduce whether our model is overfitting during training we need another dataset, namely, validation set. The validation set will show us how our model performs on out-of-sample data, i.e.&nbsp;data that have not been used in training.</p>
<p>We will generate the validation dataset by randomly sampling from the training dataset since it is much bigger than the given test set, naturally.</p>
<p>For this problem, we can assume that the images in the dataset are independent and don’t have any underlying relationship structure, like time. If this is not the case we should think about the underlying structure when splitting the dataset (more on this in later notebooks). The main aspect we should worry about is the distribution of digits in all datasets. Ideally, we want the digits to be distributed in the same way in all datasets, so when creating the dataset for validation we should keep this in mind.</p>
<p>For example, we may encounter two types of imbalance: <strong>training imbalance</strong> and <strong>testing imbalance</strong>. In training imbalance, the classes represented are not uniformly distributed, i.e.&nbsp;there is a significant perentage of one or several classes compared to the rest of the classes in the dataset. On the other hand, testing imbalance refers to the imbalance between training and testing dataset. For example, if we would have a training set with an extremly small number of say digits 3 but a large sample of digits 3 in the test set then the model has a very limited information scope to learn from, but it is expected to know 3s very well in out-of-sample settings. You can notice that in this case there is most probably evidence of both imbalance problems.</p>
<p>To begin, it is usefull to know how the labels are named. We can use <code>class_to_idx</code> to get the dictionary of labels in our dataset.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.317112Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.316641Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.326789Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.325693Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.317082Z&quot;}" data-trusted="true" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get mapping of target IDs</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data_train.class_to_idx)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{'0 - zero': 0, '1 - one': 1, '2 - two': 2, '3 - three': 3, '4 - four': 4, '5 - five': 5, '6 - six': 6, '7 - seven': 7, '8 - eight': 8, '9 - nine': 9}</code></pre>
</div>
</div>
<p>To check the distributions of labels in our training and testing dataset visually we compute a bar plot of each:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.328806Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.328446Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.658155Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.657329Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.328768Z&quot;}" data-trusted="true" data-execution_count="14">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dataframe for each dataset</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(pd.Series(data_train.targets).value_counts().reset_index())</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>df.columns <span class="op">=</span> [<span class="st">'digit'</span>, <span class="st">'count'</span>]</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>df.sort_values(<span class="st">'digit'</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>dft <span class="op">=</span> pd.DataFrame(pd.Series(data_test.targets).value_counts().reset_index())</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>dft.columns <span class="op">=</span> [<span class="st">'digit'</span>, <span class="st">'count'</span>]</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>dft.sort_values(<span class="st">'digit'</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define plot structure</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>fig,_<span class="op">=</span>plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>, figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">3</span>))</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="st">'Target distribution label'</span>, size<span class="op">=</span><span class="dv">15</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the train set</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="st">'digit'</span>, <span class="st">'count'</span>,data<span class="op">=</span>df, color<span class="op">=</span>cmap(df.digit))</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Train set'</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'digit'</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(df.digit)), df.digit)</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'count'</span>)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the test set</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="st">'digit'</span>, <span class="st">'count'</span>,data<span class="op">=</span>dft, color<span class="op">=</span>cmap(dft.digit))</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Test set'</span>, size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'digit'</span>)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(<span class="bu">len</span>(dft.digit)), dft.digit)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-13-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We can see from above figures that the target distributions for both training and test sets are similar and all digits are represented relatively in a balanced structure, which means we can just split the training data randomly into training and validation sets. As noted previously if the sample is not balanced then when splitting the sample we should preserve the sample imblance.</p>
<p>We will use <code>SubsetRandomSampler</code> to select the data. The <code>SubsetRandomSampler</code> uses indices from the original dataset to randomly and without replacement select subsets of data. So, first we need to define which indices are for the training sample and which are to be used for the validation sample. Generally, if there is no underlying structure in the data, i.e.&nbsp;the samples are independent, it is good practice to shuffle the data before selecting the indices. This ensures that we will have samples from the complete set of data. Note that the function <code>SubsetRandomSampler</code> selects random indices from the given list, however, we need to first define from which list to select these samples from.</p>
<p>We will construct the training set to be 70% of the indices of the original downloaded training dataset. The remaining 30% will be allocated to validation dataset. The steps are:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.660202Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.659620Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.944198Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.943074Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.660159Z&quot;}" data-trusted="true" data-execution_count="15">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1 - Length of train dataset from which we are splitting the data</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>Nd <span class="op">=</span> <span class="bu">len</span>(data_train)<span class="op">;</span> <span class="bu">print</span>(<span class="ss">f'Dataset length: </span><span class="sc">{</span>Nd<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 2 - Create a shuffled list of training indices to ensure</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># there are indices from the complete set in the final selection</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>Nd_idx <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(Nd))</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>np.random.shuffle(Nd_idx)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Shuffled indices </span><span class="sc">{</span>Nd_idx[:<span class="dv">5</span>]<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3 - Define percentage of indices for the training sample</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co"># to compute number of indices to be included in the training sample</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>train_pct <span class="op">=</span> <span class="fl">0.7</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>Nt <span class="op">=</span> <span class="bu">int</span>(np.floor(train_pct <span class="op">*</span> Nd))</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Number of indices to include in training set: </span><span class="sc">{</span>Nt<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 4 - Split the indices into training and validation</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>tr_idx, vl_idx <span class="op">=</span> Nd_idx[:Nt], Nd_idx[Nt:]</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Pass the indices to the SubsetRandomSampler</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>tr_sampler <span class="op">=</span> SubsetRandomSampler(tr_idx)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>vl_sampler <span class="op">=</span> SubsetRandomSampler(vl_idx)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Train idx length: </span><span class="sc">{</span><span class="bu">len</span>(tr_sampler)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(tr_sampler)[:<span class="dv">5</span>])</span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'</span><span class="ch">\n</span><span class="ss">Valid idx length: </span><span class="sc">{</span><span class="bu">len</span>(vl_sampler)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">list</span>(vl_sampler)[:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset length: 60000
Shuffled indices [8939, 47442, 57909, 43484, 27583]
Number of indices to include in training set: 42000

Train idx length: 42000
[16519, 23559, 32979, 55729, 15783]

Valid idx length: 18000
[32198, 34233, 43322, 23625, 1148]</code></pre>
</div>
</div>
<p>Now, that we have the samplers for training and validation, we can create iterable objects for each dataset which will contain all the information used in the training process with respect to the input data. These objects are called <strong>dataloaders</strong>.</p>
<p>In order to train the model using PyTorch there are two basic requirements in regards to the input data: 1. the dataset has to be in the form of a tuple with the structure (input, label) where each is a tensor 2. the input data should be stored in batches, i.e.&nbsp;the input data is iterable over batches.</p>
<p>Note that the initial data is already in form of tuples, as we saw previously. To create the iterable batches we will use a PyTorch object called <code>DataLoader</code> which takes a Python collection and converts it to an iterator based on batches. From the PyTorch documentation we have:</p>
<blockquote class="blockquote">
<p>Data loader. Combines a dataset and a sampler, and provides an iterable over the given dataset. <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoaderhttps://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">Ref</a></p>
</blockquote>
<p>Since we have datasets and the corresponding samplers we can proceed to create dataloaders, but before actually constructing dataloaders let’s check what we have got in training and validation datasets. We also need to check whether there are any partial batches, i.e.&nbsp;leftover samples when constructing mini-batches. Note that there is an option in <code>DataLoader</code> called <code>drop_last</code> to drop any such letfovers. In the function below we are computing, based on our defined <code>samplers</code>, how many batches we should expect from the datasets and whether there are letfover samples, i.e.&nbsp;incomplete batches.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.945641Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.945353Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.950212Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.949059Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.945612Z&quot;}" data-trusted="true" data-execution_count="16">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define number of batches</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>no_batches <span class="op">=</span> <span class="dv">64</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.951944Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.951562Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.962765Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.961328Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.951897Z&quot;}" data-trusted="true" data-execution_count="17">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_batches(sampler, batch_size):</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Number of samples to expect in the final dataloader</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    no_samples <span class="op">=</span> <span class="bu">len</span>(sampler)</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Number of batches to expect in the final dataloader</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    no_batches <span class="op">=</span> <span class="bu">int</span>(np.ceil(no_samples <span class="op">/</span> batch_size))</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Number of batches total: </span><span class="sc">{</span>no_batches<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Samples in the last batch (leftover samples)</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    lb_samples <span class="op">=</span> no_samples <span class="op">%</span> batch_size</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> lb_samples <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        no_batches <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Full batches: </span><span class="sc">{</span>no_batches<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> lb_samples <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'Samples in partial batch: </span><span class="sc">{</span>lb_samples<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> no_batches, lb_samples</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can apply the above function on training and validation sample:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.964317Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.964065Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.974556Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.973586Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.964292Z&quot;}" data-trusted="true" data-execution_count="18">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'Training sample'</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>tr_batches, tr_lb_samples <span class="op">=</span> check_batches(tr_sampler, no_batches)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">'</span><span class="ch">\n</span><span class="st">Validation sample'</span>)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>vl_batches, vl_lb_samples <span class="op">=</span> check_batches(vl_sampler, no_batches)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training sample
Number of batches total: 657
Full batches: 656
Samples in partial batch: 16

Validation sample
Number of batches total: 282
Full batches: 281
Samples in partial batch: 16</code></pre>
</div>
</div>
<p>Now, let’s finally create dataloaders. <strong>Note that we can not use <code>shuffle=True</code> when using <code>SubsetRandomSampler()</code> by construction.</strong></p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.975950Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.975711Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.984666Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.983757Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.975927Z&quot;}" data-trusted="true" data-execution_count="19">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Training dataloader</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>dl_train <span class="op">=</span> torch.utils.data.DataLoader(data_train, batch_size<span class="op">=</span>no_batches, </span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>                                       shuffle<span class="op">=</span><span class="va">False</span>, sampler<span class="op">=</span>tr_sampler)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Validation dataloader</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>dl_valid <span class="op">=</span> torch.utils.data.DataLoader(data_train, batch_size<span class="op">=</span>no_batches, </span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>                                       shuffle<span class="op">=</span><span class="va">False</span>, sampler<span class="op">=</span>vl_sampler)</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Test dataloader</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>dl_test <span class="op">=</span> torch.utils.data.DataLoader(data_test, batch_size<span class="op">=</span>no_batches, </span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>                                      shuffle<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>To check the size of the dataloader we can use <code>len()</code> which will give us the number of batches created for each dataset. The numbers for the batches from the dataloaders align with what we have calculated from the samplers.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.985921Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.985687Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:05.997811Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:05.997131Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.985897Z&quot;}" data-trusted="true" data-execution_count="20">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Training batches: </span><span class="sc">{</span><span class="bu">len</span>(dl_train)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Validation batches: </span><span class="sc">{</span><span class="bu">len</span>(dl_valid)<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Test batches: </span><span class="sc">{</span><span class="bu">len</span>(dl_test)<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training batches: 657
Validation batches: 282
Test batches: 157</code></pre>
</div>
</div>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Since we have constructed training and validation dataloaders from the original dataset using sampler, if we call <code>len(dl_train.dataset)</code> it will give us the number of samples of the original dataset, i.e.&nbsp;60000, and not 42000 and 18000 respectively. We will see how this applies later on in the code when we will compute the average loss and metric for the epoch of training.</p>
</div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:05.999036Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:05.998795Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:06.008651Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:06.007902Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:05.999012Z&quot;}" data-trusted="true" data-execution_count="21">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(dl_train.dataset), <span class="bu">len</span>(dl_valid.dataset))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>60000 60000</code></pre>
</div>
</div>
<p>Finally let’s check the shape of one batch:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:06.009914Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:06.009667Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:06.079367Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:06.078144Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:06.009889Z&quot;}" data-trusted="true" data-execution_count="22">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> batch <span class="kw">in</span> dl_train:</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>    X, y <span class="op">=</span> batch</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'X shape: </span><span class="sc">{</span>X<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'y shape: </span><span class="sc">{</span>y<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">break</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>X shape: torch.Size([64, 1, 28, 28])
y shape: torch.Size([64])</code></pre>
</div>
</div>
<p>So, everything looks good, we have batches with the correct number of samples and the shapes of each sample is 28 by 28 with 1 channel since the images were given in gray scale and not in RGB (then we would have 3 channels instead of 1).</p>
</section>
</section>
<section id="training-pipeline" class="level1">
<h1>Training Pipeline</h1>
<p>Now that we have our dataloaders ready we can go to the next step and define the components of the training pipeline. From Figure 1. we can see that the main components of the training pipeline are: the loss function, optimizer, metric, hyperparameters and the model architecture. We can now extend that figure to include more details on the training and validation phase</p>
<p><img src="index_files/figure-html/dae66ccc-cb16-4d2e-b75c-b84aaa7cf080.png" class="img-fluid" alt="image.png"> <cite>Figure 1. Extended overview of the components of deep learning modeling pipeline</cite><br><br></p>
<p>Let’s see briefly what each component is and why is needed.</p>
<section id="the-loss-function" class="level2">
<h2 class="anchored" data-anchor-id="the-loss-function">The Loss Function</h2>
<p>Loss function provides the connection between our model predictions and the ground truth (the target labels) in form of a measure, which tells us how far our model predictions are from the target labels. It serves as a means to verify if our optimization process of the weights is progressing as intended, i.e.&nbsp;our model is making better (more correct) predictions as we iterate the learning process.</p>
<p>The loss function needs to have certain properties to be useful in model training: 1. <strong>differentiable</strong> - if the loss function is not differentiable there are no gradients which would update the weights, without updating the weights there can be no change in the model predictions 2. <strong>sensitive</strong> - responds to small changes in weights which in turn means that it will change the prediction value. If there is no change in the prediction value the training iteration is useless. 3. It can be the same as model metric only if it satisfies the first 2 properties. For example, accuracy is a common metric (we will use it in this project) however, it is not suitable as a loss function since it is not differentiable and it does not possess the properties of sensitivity.</p>
<p>In this project the problem is of multi-class classification, and we should choose the loss function which will satisfy the above properties and provide us with the probabilities for each underlying class of labels. In most cases, cross entropy loss function is used.</p>
<p><strong>Cross-entropy loss function</strong> is made of two components: 1. the softmax activation function, and - provides prediction probabilities for each class which sum to 1 2. the negative log likelihood - since we are transforming the values from <code>(0,1)</code> by means of taking the log the output range is then <code>(log(0), log(1)) = (-inf, 0)</code> and we need to multiply with <code>(-1)</code> to get the positive loss values.</p>
<p>The cross-entropy loss is defined in PyTorch as follows:</p>
<div class="sourceCode" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate the loss function</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>loss_fun <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the loss</span></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> loss_fun(inputs, labels)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="optimizer" class="level2">
<h2 class="anchored" data-anchor-id="optimizer">Optimizer</h2>
<p>The loss function gave us the information how far our model’s outputs are from the labels. The next step is to try to minimize this loss, by adjusting the model parameters, for which we need two things: the direction to the potential minimum loss and the path to get there. The direction is given by the gradient of the loss function with respect to the parameters, while the path is given by the optimizer. The speed at which we would like to trod along this path is provided by the hyperparameter called <strong>learning rate</strong> (more on this in the next notebooks).</p>
<p>Optimizer is</p>
<p>In the figure below the process of optimizing model parameters is given:</p>
<p><img src="index_files/figure-html/c224c783-d81d-4a75-afc8-ed5d917cb09a.png" class="img-fluid" alt="image.png"> <cite>Figure 2. Process of updating the model parameters</cite></p>
<ol type="1">
<li>initialize the weights - use random values</li>
<li>for each training sample in a mini-batch use the weights to compute the prediction</li>
<li>given the calculated predictions compute the model loss on the mini-batch</li>
<li>calculate the gradients of the loss with respect to weight parameters - tells us the direction of the loss for one unit change in the parameters</li>
<li>update the weights according to step (4)</li>
<li>repeat the steps from (2) to (5)</li>
<li>iterate until the model loss is low enough and the model is not overfitting or there is a time constraint</li>
</ol>
<p>There are many optimizers to choose from like gradient descent (GD), stochastic gradient descent (SGD), Adagrad, RMSprop, Adam, etc. where GD and SGD is the first one you will most likely encounter in stuidying deep learning. For the purposes of this notebook we will use SGD and not dwelve into the details of a particular optimizers, this we leave for future notebook explainers. In PyTorch we can define it as follows:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>lr_rate)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="metric" class="level2">
<h2 class="anchored" data-anchor-id="metric">Metric</h2>
<p>The main goal of a machine learning model is to generalize well on unseen data. To assess whether we have achieved this we need an <em>independent</em> view of our model performance. Computing the model metric on the out-of-sample (validation dataset) provides us with such information.</p>
<p>During training the weights are updated using the training datset given the loss function, gradients and the optimizer. So in essence, we use training set to update (iteratively) the weights and the validation set to assess model generalization.</p>
<p>Model metric is given in terms of explainability of the model performance given the project goals. <strong>The metric needs to be “human understandable” while the loss function needs to be suitable mathematically for the optimization process (SGD).</strong></p>
<p>There may be cases where the loss function and metric are equally defined.</p>
<p>In this project, we want to see how many images are classified correctly so we can use a simple <strong>accuracy</strong> metric to acomplish this objective. There is no direct function in PyTorch for accuracy, so we define it directly within the training process with the following steps: 1. convert from model outputs to class labels by selecting the class with the highest output 2. compare model class output to labels and sum the correct predictions 3. divide the sum of correct predictions with the total number of samples</p>
</section>
<section id="hyperparameters" class="level2">
<h2 class="anchored" data-anchor-id="hyperparameters">Hyperparameters</h2>
<p>Hyperparameters are parameters that are defined before we start training and do not change during training, i.e.&nbsp;they are the parameters that are not updated. They should not be confused with weights and biases, which are trainable model parameters and are updated, i.e.&nbsp;optimized during training.</p>
<p>Examples of hyperparameters include: - batch size - number of epochs - learning rate - regularization - weight initialization</p>
<p>For this project, we will define the first three hyperparameters. The batch size we have already considered when defining the dataloaders, while the number of epochs and the learning rate is defined prior to training.</p>
<p>Note that as you change any of the hyperparameters the results of your deep learning model will change. For example, changing the learning rate has a direct effect on how fast the model converges (or doesn’t) to a solution (it might not be optimal). <em>Finding</em> the best hyperparameters for your project is one of the key components of deep learning, i.e.&nbsp;achieving optimal performance on a given task.</p>
<p>Since this is a first introductory notebook we will use only one value for the batch size, number of epochs, and learning rate. In later notebooks, we will explore the effects of the hyperparamters on the model results.</p>
</section>
<section id="model-architecture" class="level2">
<h2 class="anchored" data-anchor-id="model-architecture">Model Architecture</h2>
<p>Model architecture provides the functional form of the model. It specifies how the input samples are passed through the collection of mathematical functions to obtain the final prediction value. Model architecture is comprised of layers, namely the input layer, hidden layers and the output layer. It is the stucture of the hidden layers that leads to deep networks, i.e.&nbsp;the more hidden layers the deeper the network. Model architecture, as you could imagine, has a direct impact on the performance of our model. With bigger (deeper) architecture we can expect better model performance, however with some cavetas. We can explore these in the future notebooks. For now we will consider a simple linear neural network to illustrate the process of defining the model architecture. As mentioned earlier, the goal of this notebook is not to train the best possible model, but to explain the modeling pipeline, which can then be tuned to develop a much better performing model.</p>
<p>A simple neural network with linear layers will provide a fast baseline to check that our modeling pipeline works. So first, we define the class for model architecture by inheriting from the PyTorch <code>nn.Module</code>, which is the base class for all neural network models.</p>
<p>Within our model class we need to define the required <code>__init__</code> and <code>forward</code> methods. In order to invoke the<code>nn.Module</code> we need to add <code>super().__init__()</code> within the <code>__init__()</code> method. This ensures that <code>SimpleLNN</code> inherits all the basic functionality of <code>nn.Module</code> and it first executes the code in the parent’s class i.e.&nbsp;in <code>nn.Module</code>. The <code>forward</code> method defines how the data will pass through the defined network.</p>
<p>Let’s define the class <code>SimpleLNN</code>:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:06.081003Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:06.080657Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:06.088717Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:06.087603Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:06.080973Z&quot;}" data-trusted="true" data-execution_count="23">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SimpleLNN(nn.Module):</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co">    A simple linear neural network with 2 linear layers</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">    and an output layer with softmax activation function.</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a><span class="co">    in_shape (tuple): (height, width)</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="co">    n_out (int): number of outputs of the model</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_shape:<span class="bu">tuple</span>, n_out:<span class="bu">int</span>):</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>        torch.manual_seed(<span class="dv">1</span>)</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>        np.random.seed(<span class="dv">1</span>)</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.in_shape <span class="op">=</span> in_shape</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a>        H, W <span class="op">=</span> <span class="va">self</span>.in_shape</span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_out <span class="op">=</span> n_out</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.flatten <span class="op">=</span> nn.Flatten()</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.linear <span class="op">=</span> nn.Linear(H<span class="op">*</span>W, <span class="va">self</span>.n_out)</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.flatten(x)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> <span class="va">self</span>.linear(x)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Given our simple neural network let’s see how many parameters we have to train per each layer. We define a simple function ourselves as follows:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:06.090762Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:06.090273Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:06.100511Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:06.099316Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:06.090733Z&quot;}" data-trusted="true" data-execution_count="24">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> cnt_params(model, show_per_layer:<span class="bu">bool</span><span class="op">=</span><span class="va">True</span>):</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Get the number of model parameters for the instantiated model class.</span></span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a><span class="co">    If show_per_layer then print info for each layer.</span></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> show_per_layer:</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">75</span>)</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f'PARAMETER INFORMATION PER LAYER'</span>)</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">'•'</span><span class="op">*</span><span class="dv">75</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> name, param <span class="kw">in</span> model.named_parameters():</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> param.ndim <span class="op">&lt;</span> <span class="dv">2</span>: </span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>                in_fts <span class="op">=</span> param.ndim</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>                in_fts <span class="op">=</span> param.shape[<span class="dv">1</span>]</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>            out_fts <span class="op">=</span> param.shape[<span class="dv">0</span>]</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"Layer: </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">  | In Params: </span><span class="sc">{</span>in_fts<span class="sc">}</span><span class="ss">  | Out Params: </span><span class="sc">{</span>out_fts<span class="sc">}</span><span class="ss">  |  Total Params: </span><span class="sc">{</span>in_fts<span class="op">*</span>out_fts<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    total_cnt_params <span class="op">=</span> <span class="bu">sum</span>([x.reshape(<span class="op">-</span><span class="dv">1</span>).shape[<span class="dv">0</span>] <span class="cf">for</span> x <span class="kw">in</span> model.parameters()])</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">75</span>)</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f'Total number of parameter: </span><span class="sc">{</span>total_cnt_params<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">75</span>)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_cnt_params</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:06.102261Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:06.102020Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:06.121403Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:06.120365Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:06.102235Z&quot;}" data-trusted="true" data-execution_count="25">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleLNN((<span class="dv">28</span>,<span class="dv">28</span>), <span class="dv">10</span>)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>_ <span class="op">=</span> cnt_params(model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>---------------------------------------------------------------------------
PARAMETER INFORMATION PER LAYER
•••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••••
Layer: linear.weight  | In Params: 784  | Out Params: 10  |  Total Params: 7840
Layer: linear.bias  | In Params: 1  | Out Params: 10  |  Total Params: 10
---------------------------------------------------------------------------
Total number of parameter: 7850
---------------------------------------------------------------------------</code></pre>
</div>
</div>
</section>
</section>
<section id="training-and-validation-pipeline" class="level1">
<h1>Training and Validation Pipeline</h1>
<p>Now that we have all the components for the modeling pipeline we can go step further and define the training and validation pipeline. To illustrate the process please refer to the image below:</p>
<p><img src="index_files/figure-html/e6115414-7611-49cc-8c42-8b9e521a3bc9.png" class="img-fluid" alt="image.png"> <cite>Figure 4. Training and validation pipeline</cite><br><br></p>
<p>As you can notice we have expanded the training and validation box from previous figures to include blocks called <strong>batches</strong> and <strong>epochs</strong>.</p>
<p><strong>Batch</strong> - We have encountered batches when we createed dataloaders. As mentioned previously, number of batches can be considered as a hyperparameter, which depends on the underlying project of course. There are two extremes: - <strong>1 sample</strong> - Using only one sample would be super fast, however, we would also put all our eggs in one basket by “optimizing” (if this word can even be used here) our model based on only that one sample (surely all samples are not exactly the same). - <strong>all samples</strong> - On the other hand using all samples will provide us with the most information on how to update the weights however at the negative side of computer and time efficiency. So we need a <em>[[goldilocks mini-batch]]</em> zone. Finding this <em>goldilocks zone</em> is why this is also considered a hyperparameter, we adjust it according to the need of our model and project.</p>
<p>In later notebooks where we explain how to define a custom dataset and demonstrate different aspects of batch value on the model results.</p>
<p><strong>Epoch</strong> is one full iteration of the model, i.e.&nbsp;the model has processed all the samples once. The more epochs we add to the training process the more times the model will update its parmeters and (hopefully) learn better but not memorize results.</p>
<p>One additional information we would need for training is on which <strong>device</strong> the model will train, CPU or GPU. Hopefully, we can utilize GPU for faster learning.</p>
<p>OK, so let’s define a class <code>TrainModel</code>, which will take the inputs, process them in batches and epochs according to our model pipeline setup to return the outputs, namely trained model and training and validation loss and accuracy. Note that for the metric we will use <em>accuracy</em> since we are considering a classification problem. You can make this even more general by defining a metric as an input to the <code>TrainModel</code> class.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:06.123186Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:06.122914Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:00:06.142635Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:00:06.141610Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:06.123158Z&quot;}" data-trusted="true" data-execution_count="26">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> TrainModel:</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Training and validation of a simple neural network</span></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="co">    model: class which defines the model architecture</span></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="co">    dataloader_train: training data iterator in form of PyTorch dataloader class</span></span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="co">    dataloader_valid: validation data iterator in form of PyTorch dataloader class</span></span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="co">    no_epochs (int): number of epochs</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="co">    loss_fun: loss function</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="co">    optimizer: optimizer to be used in backpropagation</span></span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a><span class="co">    lr_rate: learning rate for updating the parameters</span></span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a><span class="co">    model_path_name (str): full path and name of the model</span></span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a><span class="co">    verbose (bool): Print statmenents</span></span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Example:</span></span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a><span class="co">    # Initialize the class with arguments</span></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="co">    tm = TrainModel(model, no_epochs=10, </span></span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a><span class="co">                    loss_fun=nn.CrossEntropyLoss(), </span></span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a><span class="co">                    optimizer = torch.optim.SGD(model.parameters(), </span></span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a><span class="co">                    lr=lr_rate), lr_rate=0.1)</span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a><span class="co">    # Train the model</span></span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a><span class="co">    model_results = tm.train(dataloader_train, dataloader_valid)</span></span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, dataloader_train, dataloader_valid, </span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>                 no_epochs, loss_fun, optimizer, lr_rate, </span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>                 model_path_name:<span class="bu">str</span>, verbose:<span class="bu">bool</span><span class="op">=</span><span class="va">None</span>):</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataloader_train <span class="op">=</span> dataloader_train</span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataloader_valid <span class="op">=</span> dataloader_valid</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.no_epochs <span class="op">=</span> no_epochs</span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss_fun <span class="op">=</span> loss_fun</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.optimizer <span class="op">=</span> optimizer</span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr_rate <span class="op">=</span> lr_rate</span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_path_name <span class="op">=</span> model_path_name</span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verbose <span class="op">=</span> verbose</span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> check_device(<span class="va">self</span>):</span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss"> device!'</span>)</span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> device</span>
<span id="cb36-43"><a href="#cb36-43" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-44"><a href="#cb36-44" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train_epoch(<span class="va">self</span>):</span>
<span id="cb36-45"><a href="#cb36-45" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Training step for one epoch</span></span>
<span id="cb36-46"><a href="#cb36-46" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb36-47"><a href="#cb36-47" aria-hidden="true" tabindex="-1"></a><span class="co">        dataloader_train: training dataloader</span></span>
<span id="cb36-48"><a href="#cb36-48" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb36-49"><a href="#cb36-49" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-50"><a href="#cb36-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the device for training</span></span>
<span id="cb36-51"><a href="#cb36-51" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> <span class="va">self</span>.check_device() </span>
<span id="cb36-52"><a href="#cb36-52" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-53"><a href="#cb36-53" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define where to save training results</span></span>
<span id="cb36-54"><a href="#cb36-54" aria-hidden="true" tabindex="-1"></a>        loss_train <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb36-55"><a href="#cb36-55" aria-hidden="true" tabindex="-1"></a>        accuracy_train <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb36-56"><a href="#cb36-56" aria-hidden="true" tabindex="-1"></a>        no_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb36-57"><a href="#cb36-57" aria-hidden="true" tabindex="-1"></a>        no_samples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb36-58"><a href="#cb36-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-59"><a href="#cb36-59" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize training mode</span></span>
<span id="cb36-60"><a href="#cb36-60" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb36-61"><a href="#cb36-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-62"><a href="#cb36-62" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Loop through the batches in the dataloader</span></span>
<span id="cb36-63"><a href="#cb36-63" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch, (X,y) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.dataloader_train):</span>
<span id="cb36-64"><a href="#cb36-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-65"><a href="#cb36-65" aria-hidden="true" tabindex="-1"></a>            <span class="co"># --- FORWARD PASS ---</span></span>
<span id="cb36-66"><a href="#cb36-66" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Input data sent to device</span></span>
<span id="cb36-67"><a href="#cb36-67" aria-hidden="true" tabindex="-1"></a>            X, y <span class="op">=</span> X.to(device), y.to(device)</span>
<span id="cb36-68"><a href="#cb36-68" aria-hidden="true" tabindex="-1"></a>            no_samples <span class="op">+=</span> X.size(<span class="dv">0</span>)</span>
<span id="cb36-69"><a href="#cb36-69" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-70"><a href="#cb36-70" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Model output - probability</span></span>
<span id="cb36-71"><a href="#cb36-71" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> <span class="va">self</span>.model(X)</span>
<span id="cb36-72"><a href="#cb36-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-73"><a href="#cb36-73" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Model prediction - class</span></span>
<span id="cb36-74"><a href="#cb36-74" aria-hidden="true" tabindex="-1"></a>            _,preds <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data,<span class="dv">1</span>)</span>
<span id="cb36-75"><a href="#cb36-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-76"><a href="#cb36-76" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Model loss &amp; accuracy</span></span>
<span id="cb36-77"><a href="#cb36-77" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> <span class="va">self</span>.loss_fun(outputs, y)</span>
<span id="cb36-78"><a href="#cb36-78" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Sum of correct predictions</span></span>
<span id="cb36-79"><a href="#cb36-79" aria-hidden="true" tabindex="-1"></a>            correct_preds <span class="op">=</span> (preds <span class="op">==</span> y).<span class="bu">sum</span>().item()</span>
<span id="cb36-80"><a href="#cb36-80" aria-hidden="true" tabindex="-1"></a>            no_correct <span class="op">+=</span> correct_preds</span>
<span id="cb36-81"><a href="#cb36-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-82"><a href="#cb36-82" aria-hidden="true" tabindex="-1"></a>            <span class="co"># --- BACKPROPAGATION ---</span></span>
<span id="cb36-83"><a href="#cb36-83" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Clear the gradients</span></span>
<span id="cb36-84"><a href="#cb36-84" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.optimizer.zero_grad()</span>
<span id="cb36-85"><a href="#cb36-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-86"><a href="#cb36-86" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Compute the gradients</span></span>
<span id="cb36-87"><a href="#cb36-87" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb36-88"><a href="#cb36-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-89"><a href="#cb36-89" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Update the parameters</span></span>
<span id="cb36-90"><a href="#cb36-90" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.optimizer.step()</span>
<span id="cb36-91"><a href="#cb36-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-92"><a href="#cb36-92" aria-hidden="true" tabindex="-1"></a>            <span class="co"># --- SAVE &amp; PRINT RESULTS ---</span></span>
<span id="cb36-93"><a href="#cb36-93" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Save results of every batch</span></span>
<span id="cb36-94"><a href="#cb36-94" aria-hidden="true" tabindex="-1"></a>            loss_train <span class="op">+=</span> loss.item()<span class="op">*</span>y.size(<span class="dv">0</span>)</span>
<span id="cb36-95"><a href="#cb36-95" aria-hidden="true" tabindex="-1"></a>            accuracy_train <span class="op">+=</span> correct_preds</span>
<span id="cb36-96"><a href="#cb36-96" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-97"><a href="#cb36-97" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Average the results</span></span>
<span id="cb36-98"><a href="#cb36-98" aria-hidden="true" tabindex="-1"></a>        loss_train <span class="op">/=</span> no_samples</span>
<span id="cb36-99"><a href="#cb36-99" aria-hidden="true" tabindex="-1"></a>        accuracy_train <span class="op">/=</span> no_samples</span>
<span id="cb36-100"><a href="#cb36-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-101"><a href="#cb36-101" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(colored(<span class="ss">f'TrLoss: </span><span class="sc">{</span>loss_train<span class="sc">}</span><span class="ss">   TrAccuracy:[</span><span class="sc">{</span>no_correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>no_samples<span class="sc">}</span><span class="ss">] </span><span class="sc">{</span>accuracy_train<span class="sc">}</span><span class="ss">'</span>, <span class="st">'blue'</span>))</span>
<span id="cb36-102"><a href="#cb36-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-103"><a href="#cb36-103" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.model, loss_train, accuracy_train</span>
<span id="cb36-104"><a href="#cb36-104" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-105"><a href="#cb36-105" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-106"><a href="#cb36-106" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> validate_epoch(<span class="va">self</span>):</span>
<span id="cb36-107"><a href="#cb36-107" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Validate the trained model for the epoch</span></span>
<span id="cb36-108"><a href="#cb36-108" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb36-109"><a href="#cb36-109" aria-hidden="true" tabindex="-1"></a><span class="co">        dataloader_valid: validation dataloader</span></span>
<span id="cb36-110"><a href="#cb36-110" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb36-111"><a href="#cb36-111" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-112"><a href="#cb36-112" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get the device for training</span></span>
<span id="cb36-113"><a href="#cb36-113" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> <span class="va">self</span>.check_device()</span>
<span id="cb36-114"><a href="#cb36-114" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-115"><a href="#cb36-115" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Define where to save training results</span></span>
<span id="cb36-116"><a href="#cb36-116" aria-hidden="true" tabindex="-1"></a>        loss_valid <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb36-117"><a href="#cb36-117" aria-hidden="true" tabindex="-1"></a>        accuracy_valid <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb36-118"><a href="#cb36-118" aria-hidden="true" tabindex="-1"></a>        no_samples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb36-119"><a href="#cb36-119" aria-hidden="true" tabindex="-1"></a>        no_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb36-120"><a href="#cb36-120" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-121"><a href="#cb36-121" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Set the evaluation mode</span></span>
<span id="cb36-122"><a href="#cb36-122" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb36-123"><a href="#cb36-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-124"><a href="#cb36-124" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb36-125"><a href="#cb36-125" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch, (Xv,yv) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.dataloader_valid):                </span>
<span id="cb36-126"><a href="#cb36-126" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb36-127"><a href="#cb36-127" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Input data sent to device</span></span>
<span id="cb36-128"><a href="#cb36-128" aria-hidden="true" tabindex="-1"></a>                Xv, yv <span class="op">=</span> Xv.to(device), yv.to(device)</span>
<span id="cb36-129"><a href="#cb36-129" aria-hidden="true" tabindex="-1"></a>                no_samples <span class="op">+=</span> Xv.size(<span class="dv">0</span>)</span>
<span id="cb36-130"><a href="#cb36-130" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb36-131"><a href="#cb36-131" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Model output - probability</span></span>
<span id="cb36-132"><a href="#cb36-132" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> <span class="va">self</span>.model(Xv)</span>
<span id="cb36-133"><a href="#cb36-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-134"><a href="#cb36-134" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Model prediction - class</span></span>
<span id="cb36-135"><a href="#cb36-135" aria-hidden="true" tabindex="-1"></a>                _,preds <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data,<span class="dv">1</span>)</span>
<span id="cb36-136"><a href="#cb36-136" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb36-137"><a href="#cb36-137" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Model loss &amp; accuracy</span></span>
<span id="cb36-138"><a href="#cb36-138" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> <span class="va">self</span>.loss_fun(outputs, yv)</span>
<span id="cb36-139"><a href="#cb36-139" aria-hidden="true" tabindex="-1"></a>                correct_preds <span class="op">=</span> (preds <span class="op">==</span> yv).<span class="bu">sum</span>().item()</span>
<span id="cb36-140"><a href="#cb36-140" aria-hidden="true" tabindex="-1"></a>                no_correct <span class="op">+=</span> correct_preds</span>
<span id="cb36-141"><a href="#cb36-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-142"><a href="#cb36-142" aria-hidden="true" tabindex="-1"></a>                <span class="co"># --- SAVE &amp; PRINT RESULTS ---</span></span>
<span id="cb36-143"><a href="#cb36-143" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Save results of every batch</span></span>
<span id="cb36-144"><a href="#cb36-144" aria-hidden="true" tabindex="-1"></a>                loss_valid <span class="op">+=</span> loss.item()<span class="op">*</span>y.size(<span class="dv">0</span>)</span>
<span id="cb36-145"><a href="#cb36-145" aria-hidden="true" tabindex="-1"></a>                accuracy_valid <span class="op">+=</span> correct_preds</span>
<span id="cb36-146"><a href="#cb36-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-147"><a href="#cb36-147" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Average the results</span></span>
<span id="cb36-148"><a href="#cb36-148" aria-hidden="true" tabindex="-1"></a>            loss_valid <span class="op">/=</span> no_samples</span>
<span id="cb36-149"><a href="#cb36-149" aria-hidden="true" tabindex="-1"></a>            accuracy_valid <span class="op">/=</span> no_samples</span>
<span id="cb36-150"><a href="#cb36-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-151"><a href="#cb36-151" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(colored(<span class="ss">f'VlLoss: </span><span class="sc">{</span>loss_valid<span class="sc">}</span><span class="ss">   VlAccuracy:[</span><span class="sc">{</span>no_correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>no_samples<span class="sc">}</span><span class="ss">] </span><span class="sc">{</span>accuracy_valid<span class="sc">}</span><span class="ss">'</span>,<span class="st">'red'</span>))</span>
<span id="cb36-152"><a href="#cb36-152" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-153"><a href="#cb36-153" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss_valid, accuracy_valid</span>
<span id="cb36-154"><a href="#cb36-154" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-155"><a href="#cb36-155" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb36-156"><a href="#cb36-156" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train(<span class="va">self</span>):</span>
<span id="cb36-157"><a href="#cb36-157" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""Training the model for N epochs"""</span></span>
<span id="cb36-158"><a href="#cb36-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-159"><a href="#cb36-159" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Initialize for results</span></span>
<span id="cb36-160"><a href="#cb36-160" aria-hidden="true" tabindex="-1"></a>        loss_train_epoch <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span><span class="va">self</span>.no_epochs</span>
<span id="cb36-161"><a href="#cb36-161" aria-hidden="true" tabindex="-1"></a>        accuracy_train_epoch <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span><span class="va">self</span>.no_epochs</span>
<span id="cb36-162"><a href="#cb36-162" aria-hidden="true" tabindex="-1"></a>        loss_valid_epoch <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span><span class="va">self</span>.no_epochs</span>
<span id="cb36-163"><a href="#cb36-163" aria-hidden="true" tabindex="-1"></a>        accuracy_valid_epoch <span class="op">=</span> [<span class="dv">0</span>]<span class="op">*</span><span class="va">self</span>.no_epochs</span>
<span id="cb36-164"><a href="#cb36-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-165"><a href="#cb36-165" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.no_epochs):</span>
<span id="cb36-166"><a href="#cb36-166" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'EPOCH: </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb36-167"><a href="#cb36-167" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">'.'</span><span class="op">*</span><span class="dv">75</span>)</span>
<span id="cb36-168"><a href="#cb36-168" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-169"><a href="#cb36-169" aria-hidden="true" tabindex="-1"></a>            model, loss_train, accuracy_train <span class="op">=</span> <span class="va">self</span>.train_epoch()</span>
<span id="cb36-170"><a href="#cb36-170" aria-hidden="true" tabindex="-1"></a>            loss_valid, accuracy_valid <span class="op">=</span> <span class="va">self</span>.validate_epoch()</span>
<span id="cb36-171"><a href="#cb36-171" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb36-172"><a href="#cb36-172" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Save results</span></span>
<span id="cb36-173"><a href="#cb36-173" aria-hidden="true" tabindex="-1"></a>            loss_train_epoch[epoch] <span class="op">=</span> loss_train</span>
<span id="cb36-174"><a href="#cb36-174" aria-hidden="true" tabindex="-1"></a>            accuracy_train_epoch[epoch] <span class="op">=</span> accuracy_train</span>
<span id="cb36-175"><a href="#cb36-175" aria-hidden="true" tabindex="-1"></a>            loss_valid_epoch[epoch] <span class="op">=</span> loss_valid</span>
<span id="cb36-176"><a href="#cb36-176" aria-hidden="true" tabindex="-1"></a>            accuracy_valid_epoch[epoch] <span class="op">=</span> accuracy_valid</span>
<span id="cb36-177"><a href="#cb36-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-178"><a href="#cb36-178" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">'-'</span><span class="op">*</span><span class="dv">75</span>)</span>
<span id="cb36-179"><a href="#cb36-179" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-180"><a href="#cb36-180" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Save model results</span></span>
<span id="cb36-181"><a href="#cb36-181" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.model_path_name:</span>
<span id="cb36-182"><a href="#cb36-182" aria-hidden="true" tabindex="-1"></a>            torch.save(model, <span class="va">self</span>.model_path_name)</span>
<span id="cb36-183"><a href="#cb36-183" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(colored(<span class="ss">f'Model saved in </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>model_path_name<span class="sc">}</span><span class="ss">'</span>,<span class="st">'blue'</span>))</span>
<span id="cb36-184"><a href="#cb36-184" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb36-185"><a href="#cb36-185" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> loss_train_epoch, loss_valid_epoch, accuracy_train_epoch, accuracy_valid_epoch</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s quickly explain how we have defined class <code>TrainModel</code>. The class <code>TrainModel</code> is composed of three methods: <code>train_epoch</code>, <code>validate_epoch</code> and <code>train</code>, where <code>train_epoch</code> and <code>validate_epoch</code> provide the training and validation for one epoch, while the <code>train</code> method encompases both to provide the complete modeling pipeline for a specified number of epochs.</p>
<p>Using <code>__init__()</code> we define all the arguments for the class.</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model, dataloader_train, dataloader_valid, </span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>                 no_epochs, loss_fun, optimizer, lr_rate, </span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>                 model_path_name:<span class="bu">str</span><span class="op">=</span><span class="va">None</span>, verbose:<span class="bu">bool</span><span class="op">=</span><span class="va">None</span>):</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataloader_train <span class="op">=</span> dataloader_train</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataloader_valid <span class="op">=</span> dataloader_valid</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.no_epochs <span class="op">=</span> no_epochs</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss_fun <span class="op">=</span> loss_fun</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.optimizer <span class="op">=</span> optimizer</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr_rate <span class="op">=</span> lr_rate</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model_path_name <span class="op">=</span> model_path_name</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.verbose <span class="op">=</span> verbose</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In addition to the above mentioned methods, we also define the <code>check_device</code> method to define on which processor the model should be trained.</p>
<div class="sourceCode" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> check_device(<span class="va">self</span>):</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>        device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.verbose:</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f'Using </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss"> device!'</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> device</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong><code>train_epoch</code></strong></p>
<p>performs one epoch of training given the training dataloader and returns training loss and metric, which we defined to be accuracy for this project. Once we have defined the device to use for training we need to define all the objects where we will save the training results. We definitely need to see the training loss and accuracy to be able to compare with the validation results, but we also would like to print the number of correct predictions for each epoch with <code>no_correct</code>. In order to average the results from all the batches we need the number of samples for the complete epoch. Recall that since we have user sampler to create training and validation using simply <code>len(dataloader_train)</code> will give the number of samples from the original dataset. So, to get the number of samples per epoch of training we will simply add the number of samples per each batch to the object <code>no_samples</code>. Note that these are all defined to start at zero since we are adding a numeric value to each as we iterate through the batches.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>loss_train <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>accuracy_train <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>no_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>no_samples <span class="op">=</span> <span class="dv">0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Next, we set the model to training mode with</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>which activates the training process, i.e.&nbsp;it activates some of the layers in our model and more specifically enables gradient computation.</p>
<p>Now we are ready to loop through the dataloader, i.e.&nbsp;through all the batches and compute the forward and backward pass of our neural network. The <strong>forward pass</strong> consists of the following:</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Input data sent to device</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> X.to(device), y.to(device)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>no_samples <span class="op">+=</span> X.size(<span class="dv">0</span>)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Model output - probability</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> <span class="va">self</span>.model(X)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Model prediction - class</span></span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>_,preds <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data,<span class="dv">1</span>)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Model loss &amp; accuracy</span></span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> <span class="va">self</span>.loss_fun(outputs, y)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Sum of correct predictions</span></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>correct_preds <span class="op">=</span> (preds <span class="op">==</span> y).<span class="bu">sum</span>().item()</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>no_correct <span class="op">+=</span> correct_preds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>As we iterate through the dataloader we extract the tuple of inputs, namely images (<code>X</code>) and labels (<code>y</code>) and send them to defined processor, either CPU or GPU. Also, we add the number of samples from this batch to the <code>no_samples</code> object. Using the model architecture defined in <code>model</code> we pass the input images through to obtain the prediction. In order to be able to compare model output to labels, we need to convert the predictions to class labels for which we use <code>torch.max(outputs.data,1)</code>. It will output the index of a maximum value given the 1 dimension. Since the labels are digits from 0 to 9, if we get the index we will still get a value from 0 to 9. Note that if this is not the case you need to additional use a mapping function which defines the labels accordingly. Next, we compute model loss given out loss function. Note that we are using cross-entropy loss, which contains softmax and the negative log likelihood, which is the reason why we have not included the softmax layer in our model architecture. Finally, we compute the metric, i.e.&nbsp;accuracy, by simply summing the correct predictions and adding the number to <code>no_correct</code> for later use.</p>
<p>Having the loss function, we can compute the <strong>backpropagation</strong>:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Clear the gradients</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.optimizer.zero_grad()</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute the gradients</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>loss.backward()</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Update the parameters</span></span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.optimizer.step()</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="co"># --- SAVE &amp; PRINT RESULTS ---</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Save results of every batch</span></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>loss_train <span class="op">+=</span> loss.item()<span class="op">*</span>y.size(<span class="dv">0</span>)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>accuracy_train <span class="op">+=</span> correct_preds</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Since the gradients accumulate as we peform multiple forward and backward passes, we need to call <code>self.optimizer.zero_grad()</code> to clear the accumulated gradients from the previous batch. Now it is safe to compute the gradients and call the <code>optimizer.step()</code> to update the weights. Remember <strong>gradients tell us how much the model loss will change for a unit change in the parameters</strong>. Lastly, we add the results of the model loss and number of correct predictions for the current batch. Note that <code>loss.item()</code> represent loss for the batch with the mean reduction. So in order to obtain the total loss for the batch we need to multiply with the size of the batch (number of samples) or <code>y.size(0)</code>. You can change the behavior of this by changing the argument <code>reduction</code> in the <code>CrossEntropyLoss</code>(<a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss">source</a>).</p>
<p>Finally, we divide the loss and metric by the number of samples to obtain the average values of each.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>You might wonder why are we dividing now and before we multiplied to get the total loss. After we trained for one epoch we need an average loss over that epoch. Now, consider that not all batches have to be of the same size and hence not all losses over each batch are on the same scale as the rest of the batches. For this reason we first multiply each batch loss with its size to get the total and then it is easy to get the epoch loss by dividing with the number of samples. Note that if all the batches are of the same size (for example you might have used the argument <code>drop_last</code> when constructing the dataloader) then you can simply add the loss.item() and get the epoch average loss by dividing with the number of batches.</p>
</div>
</div>
<div class="sourceCode" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>loss_train <span class="op">/=</span> no_samples</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>accuracy_train <span class="op">/=</span> no_samples</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(colored(<span class="ss">f'TrLoss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">}</span><span class="ss">   TrAccuracy:[</span><span class="sc">{</span>no_correct<span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>no_samples<span class="sc">}</span><span class="ss">] </span><span class="sc">{</span>accuracy_train<span class="sc">}</span><span class="ss">'</span>, <span class="st">'blue'</span>))</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a><span class="cf">return</span> <span class="va">self</span>.model, loss_train, accuracy_train    </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
<p><strong><code>valid_epoch</code></strong></p>
<p>Difference between the validation and training step is that in the validation step we are only computing the forward based on the trained model in the training step; hence no need for backpropagation since we are not updating any parameters. We simply want to deduce how well our model for a given epoch is doing on unseen (during training) data. Similarly, as in <code>train_epoch</code> we define the device to train on and the objects to store the needed results of validation.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the device for training</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="va">self</span>.check_device()</span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define where to save training results</span></span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>loss_valid <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>accuracy_valid <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>no_samples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>no_correct <span class="op">=</span> <span class="dv">0</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We set the model to evaluation mode with</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">eval</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>which tells the model to use the model architecture with the parameters, rather than activating layers for the calculation. Additionally, computation of gradients is disabled. Additionaly, to ensure no gradients are computed, the for loop over dataloader is inserted withint the <code>torch.no_grad()</code> which basically sets <code>requires_grad</code> of all tensors t <code>False</code>.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch, (Xv,yv) <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.dataloader_valid):                </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>the rest of the computation for each bach comprises of a forward pass which is the same as in training, but now we are using a different dataset and no updates to the parameters is done. We simply want the loss and metric for each batch.</p>
<hr>
<p><strong><code>train()</code></strong></p>
<p>The method <code>train()</code> encompases the previous two functions to finally create a training and validation loop. We loop through the number of epochs defined and store results for each epoch to be used later. ***</p>
</section>
<section id="train-the-model" class="level1">
<h1>Train the Model</h1>
<p>To train the model we need the following: - instantiate the model class and send it to device - define the hyperparameters - instantiate the modeling pipeline with the neccessary arguments - call the method <code>train()</code> to start training and validation</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:00:06.143961Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:00:06.143703Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:01:07.475052Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:01:07.473968Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:00:06.143935Z&quot;}" data-trusted="true" data-execution_count="27">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate the model architecture</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SimpleLNN(in_shape<span class="op">=</span>(<span class="dv">28</span>,<span class="dv">28</span>), n_out<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the hyperparameters</span></span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>no_epochs <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>loss_fun <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>lr_rate <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> torch.optim.SGD(model.parameters(), lr<span class="op">=</span>lr_rate)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Instantiate the modeling pipeline and call the `train()` method</span></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a>model_path_name <span class="op">=</span> MODELS_DIR<span class="op">/</span><span class="st">'basic_model.pt'</span></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>tm <span class="op">=</span> TrainModel(model, dl_train, dl_valid, </span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>                no_epochs, loss_fun, optimizer, lr_rate, </span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>                model_path_name)</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>model_hist <span class="op">=</span> tm.train()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>EPOCH: 1
...........................................................................
TrLoss: 0.5189617994853428   TrAccuracy:[36541/42000] 0.8700238095238095
VlLoss: 0.3891728159056769   VlAccuracy:[16030/18000] 0.8905555555555555
---------------------------------------------------------------------------
EPOCH: 2
...........................................................................
TrLoss: 0.3512501835482461   TrAccuracy:[37902/42000] 0.9024285714285715
VlLoss: 0.352610739019182   VlAccuracy:[16187/18000] 0.8992777777777777
---------------------------------------------------------------------------
EPOCH: 3
...........................................................................
TrLoss: 0.32412550860359557   TrAccuracy:[38218/42000] 0.909952380952381
VlLoss: 0.3362210586865743   VlAccuracy:[16267/18000] 0.9037222222222222
---------------------------------------------------------------------------
EPOCH: 4
...........................................................................
TrLoss: 0.309521884955111   TrAccuracy:[38398/42000] 0.9142380952380952
VlLoss: 0.3243277087741428   VlAccuracy:[16334/18000] 0.9074444444444445
---------------------------------------------------------------------------
EPOCH: 5
...........................................................................
TrLoss: 0.2999727694193522   TrAccuracy:[38493/42000] 0.9165
VlLoss: 0.31641336976157297   VlAccuracy:[16376/18000] 0.9097777777777778
---------------------------------------------------------------------------
EPOCH: 6
...........................................................................
TrLoss: 0.29298935195377895   TrAccuracy:[38554/42000] 0.917952380952381
VlLoss: 0.3123331452475654   VlAccuracy:[16385/18000] 0.9102777777777777
---------------------------------------------------------------------------
EPOCH: 7
...........................................................................
TrLoss: 0.2879661300750006   TrAccuracy:[38665/42000] 0.9205952380952381
VlLoss: 0.310020920197169   VlAccuracy:[16417/18000] 0.9120555555555555
---------------------------------------------------------------------------
EPOCH: 8
...........................................................................
TrLoss: 0.283501057159333   TrAccuracy:[38686/42000] 0.9210952380952381
VlLoss: 0.306538266075982   VlAccuracy:[16424/18000] 0.9124444444444444
---------------------------------------------------------------------------
EPOCH: 9
...........................................................................
TrLoss: 0.2798427324181511   TrAccuracy:[38723/42000] 0.9219761904761905
VlLoss: 0.30381705085436506   VlAccuracy:[16443/18000] 0.9135
---------------------------------------------------------------------------
EPOCH: 10
...........................................................................
TrLoss: 0.2769243878750574   TrAccuracy:[38785/42000] 0.9234523809523809
VlLoss: 0.3026355334917704   VlAccuracy:[16457/18000] 0.9142777777777777
---------------------------------------------------------------------------
Model saved in /kaggle/working/models/basic_model.pt</code></pre>
</div>
</div>
</section>
<section id="visualizing-model-results" class="level1">
<h1>Visualizing Model Results</h1>
<p>It would be nice to visually see the results of our training and validation. Let’s create a simple plot of loss and metric for our model:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:01:07.477007Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:01:07.476705Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:01:07.485361Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:01:07.484604Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:01:07.476977Z&quot;}" data-trusted="true" data-execution_count="28">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># loss_train_epoch, loss_valid_epoch, accuracy_train_epoch, accuracy_valid_epoch</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>model_results_colors <span class="op">=</span> [<span class="st">'#F9A302'</span>, <span class="st">'#00474C'</span>] <span class="co"># training and validation resp.</span></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_training_results(model_hist:<span class="bu">list</span>, metric_name:<span class="bu">str</span>):</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Plot the model results: loss and metric</span></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="co">    model_hist: results of a trained model as a list with the following elements: </span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a><span class="co">                training loss, validation loss, training metric, and validation metric</span></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a><span class="co">    metric_name (str): name of the metric to insert in the plot title</span></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>    plt.style.use(<span class="st">'ggplot'</span>)</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>    figsize <span class="op">=</span> (<span class="dv">12</span>,<span class="dv">4</span>)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>    fig, ax <span class="op">=</span> plt.subplots(<span class="dv">1</span>,<span class="dv">2</span>, figsize<span class="op">=</span>figsize)</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Model Loss</span></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Model Loss'</span>, size<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>    plt.plot(model_hist[<span class="dv">0</span>], lw<span class="op">=</span><span class="dv">2</span>, c<span class="op">=</span>model_results_colors[<span class="dv">0</span>], </span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>             label<span class="op">=</span><span class="st">'Training loss'</span>)</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>    plt.plot(model_hist[<span class="dv">1</span>], lw<span class="op">=</span><span class="dv">2</span>, c<span class="op">=</span>model_results_colors[<span class="dv">1</span>], </span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>             label<span class="op">=</span><span class="st">'Validation loss'</span>)</span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'loss'</span>)</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Model Metric</span></span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>)</span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Model Metric'</span>, size<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>    plt.plot(model_hist[<span class="dv">2</span>], lw<span class="op">=</span><span class="dv">2</span>, c<span class="op">=</span>model_results_colors[<span class="dv">0</span>],  </span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a>             label<span class="op">=</span><span class="ss">f'Training </span><span class="sc">{</span>metric_name<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a>    plt.plot(model_hist[<span class="dv">3</span>], lw<span class="op">=</span><span class="dv">2</span>, c<span class="op">=</span>model_results_colors[<span class="dv">1</span>], </span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a>             label<span class="op">=</span><span class="ss">f'Validation </span><span class="sc">{</span>metric_name<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epoch'</span>)</span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="ss">f'</span><span class="sc">{</span>metric_name<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb49-36"><a href="#cb49-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:01:07.487034Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:01:07.486526Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:01:07.821596Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:01:07.820530Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:01:07.487002Z&quot;}" data-trusted="true" data-execution_count="29">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>plot_training_results(model_hist, <span class="st">'accuracy'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-28-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Furthermore, of great interest is to analyze where our model makes the most mistakes, i.e.&nbsp;for which classes. We can visualize the class predictions given model outputs and the labels using the confusion matrix. We can use the final saved model and compute predictions on the validation set. Let’s define a new function for this:</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:01:07.823034Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:01:07.822768Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:01:07.830494Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:01:07.829628Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:01:07.823006Z&quot;}" data-trusted="true" data-execution_count="30">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_confusion_matrix(conf_mat):</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Plot confusion matrix from the pandas crosstab computation."""</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define custom cmap</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    cmap_ofd <span class="op">=</span> mcolors.LinearSegmentedColormap.from_list(<span class="st">'diagonal'</span>, </span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>                                                         [<span class="st">'#4F4D8C'</span>,<span class="st">'#2E4159'</span>], N<span class="op">=</span><span class="dv">256</span>)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>    cmap_d <span class="op">=</span> mcolors.LinearSegmentedColormap.from_list(<span class="st">'off diagonal'</span>, </span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>                                                       [<span class="st">'#F2F2F0'</span>,<span class="st">'#5F5DA6'</span>], N<span class="op">=</span><span class="dv">256</span>)</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">5</span>))</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Complete plot</span></span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> sns.heatmap(conf_mat, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span>cmap_ofd, fmt<span class="op">=</span><span class="st">'d'</span>, cbar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Overlay the diagonal</span></span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>    ax <span class="op">=</span> sns.heatmap(conf_mat, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span>cmap_d, fmt<span class="op">=</span><span class="st">'d'</span>, </span>
<span id="cb51-15"><a href="#cb51-15" aria-hidden="true" tabindex="-1"></a>                     mask<span class="op">=</span>np.eye(<span class="bu">len</span>(conf_mat)), cbar<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb51-16"><a href="#cb51-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-17"><a href="#cb51-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Place x-axis labels and ticks on top</span></span>
<span id="cb51-18"><a href="#cb51-18" aria-hidden="true" tabindex="-1"></a>    ax.xaxis.tick_top()</span>
<span id="cb51-19"><a href="#cb51-19" aria-hidden="true" tabindex="-1"></a>    ax.xaxis.set_label_position(<span class="st">'top'</span>)</span>
<span id="cb51-20"><a href="#cb51-20" aria-hidden="true" tabindex="-1"></a>    ax.yaxis.set_label(<span class="st">'Prediction Class'</span>)</span>
<span id="cb51-21"><a href="#cb51-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-22"><a href="#cb51-22" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Other styling options</span></span>
<span id="cb51-23"><a href="#cb51-23" aria-hidden="true" tabindex="-1"></a>    ax.set_yticklabels(ax.get_yticklabels(), va<span class="op">=</span><span class="st">'center'</span>)</span>
<span id="cb51-24"><a href="#cb51-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb51-25"><a href="#cb51-25" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Actual Class'</span>)</span>
<span id="cb51-26"><a href="#cb51-26" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Prediction Class'</span>)</span>
<span id="cb51-27"><a href="#cb51-27" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb51-28"><a href="#cb51-28" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:01:07.832977Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:01:07.832314Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:01:07.844700Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:01:07.843779Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:01:07.832920Z&quot;}" data-trusted="true" data-execution_count="31">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> model_confusion_matrix(model_path_name, dataloader):</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Compute model predictions on a given dataloader </span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a><span class="co">    and plot the confusion matrix"""</span></span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the saved model</span></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> torch.load(model_path_name)</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set the model into evaluation mode</span></span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Object to save class prediction across batches</span></span>
<span id="cb52-12"><a href="#cb52-12" aria-hidden="true" tabindex="-1"></a>    preds_class <span class="op">=</span> torch.empty((<span class="dv">0</span>,))</span>
<span id="cb52-13"><a href="#cb52-13" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> torch.empty((<span class="dv">0</span>,))</span>
<span id="cb52-14"><a href="#cb52-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-15"><a href="#cb52-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb52-16"><a href="#cb52-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch, (Xv,yv) <span class="kw">in</span> <span class="bu">enumerate</span>(dataloader):                </span>
<span id="cb52-17"><a href="#cb52-17" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Input data sent to device</span></span>
<span id="cb52-18"><a href="#cb52-18" aria-hidden="true" tabindex="-1"></a>            Xv, yv <span class="op">=</span> Xv.to(device), yv.to(device)</span>
<span id="cb52-19"><a href="#cb52-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-20"><a href="#cb52-20" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Model output - probability</span></span>
<span id="cb52-21"><a href="#cb52-21" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(Xv)</span>
<span id="cb52-22"><a href="#cb52-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-23"><a href="#cb52-23" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Model prediction - class</span></span>
<span id="cb52-24"><a href="#cb52-24" aria-hidden="true" tabindex="-1"></a>            _,preds <span class="op">=</span> torch.<span class="bu">max</span>(outputs.data,<span class="dv">1</span>)</span>
<span id="cb52-25"><a href="#cb52-25" aria-hidden="true" tabindex="-1"></a>            preds_class <span class="op">=</span> torch.cat((preds_class, preds))</span>
<span id="cb52-26"><a href="#cb52-26" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> torch.cat((labels, yv))</span>
<span id="cb52-27"><a href="#cb52-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-28"><a href="#cb52-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ----- CONFUSION MATRIX PLOT -----</span></span>
<span id="cb52-29"><a href="#cb52-29" aria-hidden="true" tabindex="-1"></a>    ct <span class="op">=</span> pd.crosstab(preds_class.<span class="bu">int</span>(), labels.<span class="bu">int</span>(), </span>
<span id="cb52-30"><a href="#cb52-30" aria-hidden="true" tabindex="-1"></a>                     rownames<span class="op">=</span>[<span class="st">'Prediction'</span>], colnames<span class="op">=</span>[<span class="st">'Actual'</span>])</span>
<span id="cb52-31"><a href="#cb52-31" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb52-32"><a href="#cb52-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> preds_class, labels, ct</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>From the figure below we can now analyze where our model makes mistakes by comparing the predicted and actual class. It is no surprise that the largest numbers will be on the diagonal, i.e.&nbsp;the number of images that the model predicted correctly. All the values off the diagonal are misclassified images. Our objective is to reduce these values as much as we can.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:01:07.846706Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:01:07.846071Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:01:11.005447Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:01:11.004365Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:01:07.846674Z&quot;}" data-trusted="true" data-execution_count="32">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>pc,lc,conf_mat <span class="op">=</span> model_confusion_matrix(model_path_name, dl_valid)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>plot_confusion_matrix(conf_mat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-31-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>In addition to above graphs, we can also see for which class the model makes the most mistakes regardless of what the prediction class is.</p>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:01:11.006883Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:01:11.006557Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:01:11.014531Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:01:11.013737Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:01:11.006855Z&quot;}" data-trusted="true" data-execution_count="33">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> misclass(pc, lc):</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>    plt.style.use(<span class="st">'ggplot'</span>)</span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.DataFrame({<span class="st">'preds'</span>: pc.numpy(),</span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>                       <span class="st">'labels'</span>: lc.numpy()})</span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'misclass'</span>] <span class="op">=</span> (df.preds <span class="op">!=</span> df.labels).astype(<span class="st">'int'</span>)</span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'labels'</span>] <span class="op">=</span> df[<span class="st">'labels'</span>].astype(<span class="st">'int'</span>)</span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>    df[<span class="st">'miss_per_class'</span>] <span class="op">=</span> df.groupby(<span class="st">'labels'</span>)[<span class="st">'misclass'</span>]<span class="op">\</span></span>
<span id="cb54-8"><a href="#cb54-8" aria-hidden="true" tabindex="-1"></a>                             .transform(<span class="st">'sum'</span>)</span>
<span id="cb54-9"><a href="#cb54-9" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> df[[<span class="st">'labels'</span>, <span class="st">'miss_per_class'</span>]]<span class="op">\</span></span>
<span id="cb54-10"><a href="#cb54-10" aria-hidden="true" tabindex="-1"></a>            .drop_duplicates()<span class="op">\</span></span>
<span id="cb54-11"><a href="#cb54-11" aria-hidden="true" tabindex="-1"></a>            .reset_index(drop<span class="op">=</span><span class="va">True</span>)<span class="co">#set_index('labels')</span></span>
<span id="cb54-12"><a href="#cb54-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb54-13"><a href="#cb54-13" aria-hidden="true" tabindex="-1"></a>    sns.barplot(x<span class="op">=</span><span class="st">'miss_per_class'</span>, y<span class="op">=</span><span class="st">'labels'</span>, data<span class="op">=</span>df, orient<span class="op">=</span><span class="st">'h'</span>, </span>
<span id="cb54-14"><a href="#cb54-14" aria-hidden="true" tabindex="-1"></a>                palette<span class="op">=</span><span class="st">'GnBu'</span>)</span>
<span id="cb54-15"><a href="#cb54-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb54-16"><a href="#cb54-16" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Number of wrong classifications per class'</span>, size<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb54-17"><a href="#cb54-17" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Actual Class'</span>, size<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb54-18"><a href="#cb54-18" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2023-04-04T18:01:11.016475Z&quot;,&quot;iopub.status.busy&quot;:&quot;2023-04-04T18:01:11.015571Z&quot;,&quot;iopub.status.idle&quot;:&quot;2023-04-04T18:01:11.272002Z&quot;,&quot;shell.execute_reply&quot;:&quot;2023-04-04T18:01:11.270848Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2023-04-04T18:01:11.016443Z&quot;}" data-trusted="true" data-execution_count="34">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>misclass(pc, lc)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="index_files/figure-html/cell-33-output-1.png" class="img-fluid"></p>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">Copyright 2022, Ita Ćirović Donev</div>   
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/itacdonev">
      <i class="bi bi-github" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/itacdonevFM">
      <i class="bi bi-twitter" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/ita-cirovic-donev-9821379/">
      <i class="bi bi-linkedin" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>



<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>